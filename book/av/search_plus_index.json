{"./":{"url":"./","title":"前言","keywords":"","body":"简介如何学习音视频对于零基础参考简介 学习音视频知识的一个记录地 如何学习音视频 对于零基础 在音视频方面是零基础，也没学过任何数字信号处理相关知识，数学基础基本是高中水准，但是熟悉 C/C++ 开发 着重研究两个开源项目 ffmpeg 和 webRTC，主要看ffmpeg的视频部分和webRTC的音频部分。 视频 从视频解码入手，调用ffmpeg视频解码的基本代码只有100行左右，视频解码只要搞懂h.264，大部分场景都是这个编码格式，了解基本的 H.264 的 sps、pps、NAL等文件格式概念，了解YUV图像格式原理，了解YUV到RGB的转换，这样就可以做图像渲染，可以实现一个简单的视频播放器。 学习视频编码，建议从x264入手，一个简单的调用x264的编码代码也不到100行。编码比解码复杂在于，解码是不需要配置什么参数的，而编码有大量参数需要配置，初期只要了解几个基本概念就好了，比如 帧速率, 常用流控方式 ABR CRF，GOP，I/B/P Frame分别是什么意思。 音频 初期只需要了解两种编码器EAAC+和Silk，了解 声道，采样率等概念，了解 Wave文件格式。可以做一个简单音频播放器。 音频复杂的地方不是编解码，而是音效，看下 webRTC里的 Audio Processing module，理解以下几个概念，去噪NS，消回声AEC，静音检测VAD，自动增益控制AGC，webRTC内置的这几个算法虽然不是最好的，但是可以解决90%+的问题了，值得学习下。 路线 算法路线 要学数学，数字信号处理背后是大量的数学基础理论。 工程路线 学习跨平台开发，学习多个平台下音视频的采集，播放和处理，学习多平台下汇编语言优化。 参考 csdn雷霄骅 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/video/yuv/":{"url":"docs/video/yuv/","title":"YUV","keywords":"","body":"YUV相关部分 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/video/yuv/yuv.html":{"url":"docs/video/yuv/yuv.html","title":"yuv像素数据基本处理方法","keywords":"","body":"yuv像素数据处理处理方法yuv420处理yuv444处理灰度图亮度调节yuv像素数据处理 本篇主要是对yuv视频像素数据的非常简单的处理. 对于零基础的来说, 简单易懂. yuv420原图: 像素: 256 * 256 yuv444原图: 像素 256 * 256 处理方法 yuv420处理 分离yuv420图片像素数据中的y, u, v分量 yuv420像素数据中, 其中y分量占 前w * h byte的存储, 接着是u分量, 占w * h * 1 / 4 byte存储, 最后是 v分量 , 也是 w * h * 1 / 4 byte存储 //*************************************************************** // @file: yuv420_split.c // @author: dingfang // @date 2019-02-25 14:16:02 //*************************************************************** #include #include //yuv420 /* * 函数说明: 传入yuv图片url和yuv图片的长宽分离出图片的y,u,v分量 * 参数: url 图片的地址 * w yuv图片的宽 * h yuv图片的高 * */ int yuv420_split(const char *url, int w, int h) { FILE *fp= fopen(url, \"rb+\"); if (fp == NULL) { printf(\"图片文件打开错误\\n\"); return -1; } FILE *fp_y= fopen(\"420_y.y\", \"wb+\"); FILE *fp_u= fopen(\"420_u.y\", \"wb+\"); FILE *fp_v= fopen(\"420_v.y\", \"wb+\"); unsigned char *pic = (unsigned char *)malloc(w * h * 3 / 2); fread(pic, 1, w * h * 3 / 2, fp); fwrite(pic, 1, w * h, fp_y);//像素: w * h fwrite(pic + w * h, 1, w * h / 4, fp_u);//像素: w/2 * h/2 fwrite(pic + w * h * 5 / 4, 1, w * h / 4, fp_v);//像素: w/2 * h/2 free(pic); pic = NULL; fclose(fp); fclose(fp_y); fclose(fp_u); fclose(fp_v); return 0; } int main(void) { yuv420_split(\"./yuv420.yuv\", 256, 256); return 0; } 分离后效果 y分量: 像素: 256 * 256 u分量: 像素: 128 * 128 v分量: 像素 128 * 128 yuv444处理 分离yuv444图片像素数据中的y, u, v分量 yuv444像素数据中, 其中y分量占 前w * h byte的存储, 接着是u分量, 占w * h byte存储, 最后是 v分量 , 也是 w * h byte存储 //*************************************************************** // @file: yuv444.split.c // @author: dingfang // @date 2019-02-25 15:38:00 //*************************************************************** #include #include //yuv444 /* * 函数说明: 传入yuv图片url和yuv图片的长宽分离出图片的y,u,v分量 * 参数: url 图片的地址 * w yuv图片的宽 * h yuv图片的高 * */ int yuv444_split(const char *url, int w, int h) { FILE *fp= fopen(url, \"rb+\"); if (fp == NULL) { printf(\"图片文件打开错误\\n\"); return -1; } FILE *fp_y= fopen(\"444_y.y\", \"wb+\"); FILE *fp_u= fopen(\"444_u.y\", \"wb+\"); FILE *fp_v= fopen(\"444_v.y\", \"wb+\"); unsigned char *pic = (unsigned char *)malloc(w * h * 3); fread(pic, 1, w * h * 3, fp); fwrite(pic, 1, w * h, fp_y);//像素: w * h fwrite(pic + w * h, 1, w * h, fp_u);//像素: w * h fwrite(pic + w * h * 2 , 1, w * h, fp_v);//像素: w * h free(pic); pic = NULL; fclose(fp); fclose(fp_y); fclose(fp_u); fclose(fp_v); return 0; } int main(void) { yuv444_split(\"./yuv444.yuv\", 256, 256); return 0; } 分离后效果 y分量: 像素: 256 * 256 u分量: 像素: 256 \\* 256 v分量: 像素: 256 * 256 灰度图 将yuv420图片像素数据去掉颜色(变成灰度图) 要把yuv格式的像素数据变成灰度图像, 只需要把u和v分量设置成128即可,这是因为U、V是图像中的经过偏置处理的色度分量。色度分量在偏置处理前的取值范围是-128至127，这时候的无色对应的是“0”(最小值)值。经过偏置后色度分量取值变成了0至255，因而此时的无色对应的就是128了 //*************************************************************** // @file: yuv420_gray.c // @author: dingfang // @date 2019-02-25 15:51:08 //*************************************************************** #include #include #include /* * 函数说明: 把yuv420图片去掉颜色(变成灰度图) * 参数: url 图片的地址 * w yuv图片的宽 * h yuv图片的高 * */ int yuv420_gray(const char *url, int w, int h) { FILE *fp= fopen(url, \"rb+\"); FILE *fp_g= fopen(\"yuv420_gray.yuv\", \"wb+\"); if (fp == NULL) { printf(\"图片文件打开错误\\n\"); return -1; } unsigned char *pic = (unsigned char *)malloc(w * h * 3 / 2); fread(pic, 1, w * h * 3 / 2, fp); memset(pic + w * h, 128, w * h / 2);//128对应的是无色//把u, v分量设置成128即成为灰度图像 fwrite(pic, 1, w * h * 3 / 2, fp_g); free(pic); pic = NULL; fclose(fp); fclose(fp_g); return 0; } int main(void) { yuv420_gray(\"./yuv420.yuv\", 256, 256); return 0; } 处理后效果 效果图: 像素 256 * 256 亮度调节 将yuv420图片像素数据的亮度进行调节 调节亮度时控制好y分量的值得大小, 就能改变亮度. y分量取值是0~255, 如果取的权重大于1, 有可能会使计算结果超过255反而从0开始, 打不到增亮的效果, 所以测试的时候我是取权重为0~1的值. 保证计算后的y分量不可能大于255. //*************************************************************** // @file: yuv420_adjust_brightness.c // @author: dingfang // @date 2019-02-25 16:46:05 //*************************************************************** #include #include /* * 函数说明: 调节yuv420图片的亮度 * 参数: url 图片的路径 * w 图片的宽 * h 图片的高 * weight 调节亮度的权重//取值范围0~1 * */ int yuv420_adjust_brightness(const char *url, int w, int h, float weight) { FILE *fp= fopen(url, \"rb+\"); FILE *fp_out= fopen(\"yuv420_ab.yuv\", \"wb+\"); if (fp == NULL) { printf(\"图片文件打开失败\\n\"); return -1; } unsigned char * pic = (unsigned char *)malloc(w * h * 3 / 2); fread(pic, 1, w * h * 3 / 2, fp); for (int i = 0; i 处理后效果 效果图: 亮度调整为原图的一半, 像素 256 * 256 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/video/yuv/yuv2.html":{"url":"docs/video/yuv/yuv2.html","title":"yuv像素数据基本处理方法2","keywords":"","body":"yuv像素数据处理2处理方法添加边框梯度颜色计算psnryuv像素数据处理2 yuv420原图: 像素: 256 * 256 yuv420受损图: 处理方法 添加边框 yuv420像素数据的周围添加边框 把图片的四周用其它的颜色填充,生成边框. 我把边框位置的值都设置成255填充. yuv420像素数据存储形式和二维数组很像, 就像把一个二维数组的四周修改成其它相同的数值, 中心部分的不变, 就能让四周生成边框. //*************************************************************** // @file: yuv420_border.c // @author: dingfang // @date 2019-02-26 09:31:30 //*************************************************************** #include #include /* * 函数说明: 将yuv420像素数据的周围添加边框 * 参数: url 图片的路径 * w 图片的宽 * h 图片的高 * border 边框的宽度 * */ int yuv420_border(const char *url, int w, int h, int border) { FILE *fp_b= fopen(\"./yuv420_border.yuv\", \"wb+\"); FILE *fp= fopen(url, \"rb+\"); if (fp == NULL) { printf(\"图片文件打开失败\\n\"); return -1; } unsigned char *pic = (unsigned char *)malloc(w * h * 3 / 2); fread(pic, 1, w * h * 3 / 2, fp); for (int i = 0; i = w - border || i >= h - border) { pic[i * w + j] = 0; } } } fwrite(pic, 1, w * h * 3 / 2, fp_b); free(pic); pic = NULL; fclose(fp_b); fclose(fp); return 0; } int main(void) { yuv420_border(\"./yuv420.yuv\", 256, 256, 40); return 0; } 处理后效果 梯度颜色 生成一个阶梯式的yuv图像数据图片 只需把y分量的值阶梯式的设置, y分量存储顺序类似于二维数组, 一个矩阵就是一个图像的y分量分布, 保证每一个列宽的y分量值相等, 就可以生成一个阶梯形式的yuv图像. u和v分量设置为无色即可 //*************************************************************** // @file: yuv420_graybar.c // @author: dingfang // @date 2019-02-26 10:39:07 //*************************************************************** #include #include /* * 函数说明: 生成一个灰阶图 * 参数 w 图片的宽度 * h 图片的高度 * ymin 灰度开始的最小值 * ymax 灰度结束的最大值 * barnum 决定相邻灰度差值(ymax - ymin的值越小, barnum的值越大, 灰度差越小) * url 生成图片的url * */ int yuv420_graybar(int w, int h, int ymin, int ymax, int barnum, const char *url) { FILE *fp = fopen(url, \"wb+\"); unsigned char *pic = (unsigned char *)malloc(w * h * 3 / 2); float lun_inc = (float)(ymax - ymin) / (float)(barnum); for (int i = 0; i 处理后效果 计算psnr psnr百度百科 计算两个yuv420像素数据的psnr 有yuv420原图和yuv420受损图像计算. 对于8bit量化的像素数据来说，PSNR的计算公式如下所示。 上述公式中mse的计算公式如下所示。 其中M，N分别为图像的宽高, xij和yij分别为两张图像的每一个像素值. //*************************************************************** // @file: yuv420_psnr.c // @author: dingfang // @date 2019-02-26 17:24:45 //*************************************************************** #include #include #include /* * 函数说明: 计算两个yuv420像素数据的PSRN * 参数: url1 图片1的url * url2 图片2的url * w 图片的宽 * h 图片的高 * */ int yuv420_psnr(const char *url1, const char *url2, int w, int h) { FILE *fp1= fopen(url1, \"rb+\"); FILE *fp2= fopen(url2, \"rb+\"); if (fp1 == NULL || fp2 == NULL) { printf(\"图片文件打开失败 !\"); return -1; } unsigned char *pic1 = (unsigned char *)malloc(w * h); unsigned char *pic2 = (unsigned char *)malloc(w * h); fread(pic1, 1, w * h, fp1); fread(pic2, 1, w * h, fp2); double mse= 0; double psnr= 0; double mse_sum= 0; for (int i = 0; i Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/video/rgb/":{"url":"docs/video/rgb/","title":"RGB","keywords":"","body":"参考RGB相关部分 参考 雷神 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/video/rgb/rgb.html":{"url":"docs/video/rgb/rgb.html","title":"rgb像素数据基本处理方法","keywords":"","body":"rgb像素数据处理处理方法分离rgbrgb转bmprgb像素数据处理 rgb24像素数据原图: 像素 500 x 500 rgb24像素数据原图: 像素 256 x 256 处理方法 分离rgb 分离出rgb24像素数据的R, G, B分量 rgb24格式的每个像素的三个分量是连续存储的. 一帧宽高分别为w、h的RGB24图像一共占用w * h * 3 Byte的存储空间。RGB24格式规定首先存储第一个像素的R、G、B，然后存储第二个像素的R、G、B…以此类推. //*************************************************************** // @file: rgb24_split.c // @author: dingfang // @date 2019-02-27 09:06:36 //*************************************************************** #include #include /* * 函数说明: 分离rgb24像素数据的r,g,b分量 * 参数: url 图片的rul * w 图片的宽 * h 图片的高 * */ int rgb24_split(const char *url, int w, int h) { FILE *fp= fopen(url, \"rb+\"); FILE *fp_r= fopen(\"rgb24_r.y\", \"wb+\"); FILE *fp_g= fopen(\"rgb24_g.y\", \"wb+\"); FILE *fp_b= fopen(\"rgb24_b.y\", \"wb+\"); unsigned char *pic = (unsigned char *)malloc(w * h * 3); fread(pic, 1, w * h * 3, fp); for (int i = 0; i 效果图 R分量: 像素 500x500 G分量: 像素 500 x 500 B分量: 像素 500 x 500 rgb转bmp 将rgb24格式像素数据封装成bmp图像 在rgb数据前面加上特定的文件头之后, 再把r和b的位置进行互换. 最后写入文件, 就生成了bmp图像文件 //*************************************************************** // @file: rgb24_to_bmp.c // @author: dingfang // @date 2019-02-27 13:42:02 //*************************************************************** #include #include typedef struct _T_BmpHead { #if 0 unsigned short intbfType; unsigned int32_tbfSize; unsigned short intbfReserverd1; unsigned short intbfReserverd2; unsigned int32_tbfbfoffBits; #endif int32_t imageSize; int32_t blank; int32_t startPosition; }BmpHead_T; typedef struct _T_InfoHead { #if 0 int32_tbiSize; int32_tbiWidth; int32_tbiHeight unsigned short int biPlanes; unsigned short int biBitcount; int32_tbiCompression; int32_tbiSizeImage; int32_tbiXPelsPermeter; int32_tbiYPelsPermeter; int32_tbiClrUsed; int32_tbiClrImportant; #endif int32_t length; int32_t width; int32_t height; unsigned short int colorPlane; unsigned short int bitColor; int32_t zipFormat; //unsigned short int zipFormat; int32_t realSize; int32_t xPels; int32_t yPels; int32_t colorUse; int32_t colorImportant; }InfoHead_T; void swap_char(unsigned char *a, unsigned char *b) { char tmp = *a; *a = *b; *b = tmp; return ; } /* * 函数说明: 将rgb24像素数据封装成bmp图像 * 参数 rgb24path rgb24的路径 * w 数据的宽 * h 数据的高 * bmppath bmp图像的路径 * */ int reg24_to_bmp(const char *rgb24path, int w, int h, const char *bmppath) { FILE *fp_rgb24 = fopen(rgb24path, \"rb+\"); if (fp_rgb24 == NULL) { printf(\"rgb24文件打开失败\\n\"); return -1; } FILE *fp_bmp = fopen(bmppath, \"wb+\"); BmpHead_TbmpHeader= { 0 }; InfoHead_TinfoHeader= { 0 }; char bfType[2] = {'B', 'M'}; int headerSize = sizeof(bfType) + sizeof(BmpHead_T) + sizeof(InfoHead_T); unsigned char *rgb24_buffer = (unsigned char *)malloc(w * h * 3); fread(rgb24_buffer, 1, w * h * 3, fp_rgb24); bmpHeader.imageSize = w * h * 3 + headerSize; bmpHeader.startPosition = headerSize; infoHeader.length= sizeof(InfoHead_T); infoHeader.width= w; infoHeader.height= h; infoHeader.realSize= 3 * w * h; infoHeader.colorPlane= 1; infoHeader.bitColor= 24; fwrite(bfType, 1, sizeof(bfType), fp_bmp); fwrite(&bmpHeader, 1, sizeof(bmpHeader), fp_bmp); fwrite(&infoHeader, 1, sizeof(infoHeader), fp_bmp); #if 1 for (int i = 0; i 效果图 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/video/rgb/rgb2.html":{"url":"docs/video/rgb/rgb2.html","title":"rgb像素数据基本处理方法2","keywords":"","body":"rgb像素数据处理处理方法rgb转yuv420生成rgb24格式的彩色数据rgb像素数据处理 rgb24像素数据原图: 像素 256 x 256 处理方法 rgb转yuv420 rgb24像素数据转yuv420像素数据 rgb24转yuv420公式: y = (R 66 + G 129 + B * 25 + 128) / 256) + 16; u = (R -38 - G 74 + B * 112 + 128) / 256) + 128; v = (R 112 - G 94 - B * 18 + 128) / 256) + 128; y分量正常计算赋值, u和v分量采取水平和竖直方向取样为y分量的一半. //*************************************************************** // @file: rgb24_to_yuv420.c // @author: dingfang // @date 2019-02-28 09:31:20 //*************************************************************** #include #include /* * 函数说明: 将一个rgb24像素数据转成yuv420像素数据 * 参数 rgbUrl rgb数据的url * w 数据的宽 * h 数据的高 * yuvUrl yuv420数据的url * */ int rgb24_to_yuv420(const char *rgbUrl, int w, int h, const char *yuvUrl) { FILE *fp_rgb = fopen(rgbUrl, \"rb+\"); if (fp_rgb == NULL) { printf(\"rgb24数据打开失败!\\n\"); return -1; } FILE *fp_yuv = fopen(yuvUrl, \"wb+\"); unsigned char *rgb = (unsigned char *)malloc(w * h * 3); unsigned char *yuv_y = (unsigned char *)malloc(w * h); unsigned char *yuv_u = (unsigned char *)malloc(w * h / 4); unsigned char *yuv_v = (unsigned char *)malloc(w * h / 4); fread(rgb, 1, w * h * 3, fp_rgb); unsigned char y, u, v; for(int i = 0; i >8) + 16; u = (unsigned char)((rgb[idx * 3] * -38 - rgb[idx * 3 + 1] * 74 + rgb[idx * 3 + 2] * 112 + 128) >> 8) + 128; v = (unsigned char)((rgb[idx * 3] * 112 - rgb[idx * 3 + 1] * 94 - rgb[idx * 3 + 2] * 18 + 128) >>8) + 128; //*(py++) = y; yuv_y[idx] = y; if (i % 2 == 0 && j % 2 == 0) { yuv_u[(i / 2 * w + j) / 2] = u; } else { if (j % 2 == 0) { yuv_v[(i / 2 * w + j) / 2] = v; } } #endif #if 1 yuv_y[idx] = (unsigned char)(rgb[idx * 3] * 0.299 + rgb[idx * 3 + 1] * 0.587 + rgb[idx * 3 + 2] *0.114) + 16; if (i % 2 == 0 && j % 2 == 0) { yuv_u[(i / 2 * w + j) / 2] = (unsigned char)(rgb[idx * 3] * -0.147 + rgb[idx * 3 + 1] * -0.289 + rgb[idx * 3 + 2] * 0.436) + 128; } else { if (j % 2 == 0) { yuv_v[(i / 2 * w + j) / 2] = (unsigned char)(rgb[idx * 3] * 0.615 + rgb[idx * 3 +1] * -0.515 + rgb[idx * 3 + 2] * -0.100) + 128; } } #endif } } fwrite(yuv_y, 1, w * h, fp_yuv); fwrite(yuv_u, 1, w * h / 4, fp_yuv); fwrite(yuv_v, 1, w * h / 4, fp_yuv); free(rgb); rgb = NULL; free(yuv_y); yuv_y = NULL; free(yuv_u); yuv_u = NULL; free(yuv_v); yuv_v = NULL; fclose(fp_rgb); fclose(fp_yuv); return 0; } int main (void) { rgb24_to_yuv420(\"./rgb24_256x256.rgb\", 256, 256, \"./rgb_to_yuv420.yuv\"); return 0; } 转换后的yuv420图像: 像素 256x256 生成rgb24格式的彩色数据 生成rgb24格式的彩条数据 //*************************************************************** // @file: rgb24_colorbar.c // @author: dingfang // @date 2019-02-28 18:28:15 //*************************************************************** #include #include /* * 函数说明: 生成一个rgb24格式的彩条图 * 参数 w rgb数据的宽 * h rgb数据的高 * url 生成的rgb数据的url * */ int rgb24_colorbar(int w, int h, const char *url) { FILE *fp = fopen(url, \"wb+\"); unsigned char *pic = (unsigned char *)malloc(w * h * 3); /*--------------------白 黄 青 绿 品 红 蓝 黑 ---*/ unsigned char r[8] = {255, 255, 0, 0, 255, 255, 0, 0}; unsigned char g[8] = {255, 255, 255, 255, 0, 0, 0, 0}; unsigned char b[8] = {255, 0, 255, 0, 255, 0, 255, 0}; int barW = w / 8; for (int i = 0; i 代码中的r, g, b三个数组我已经进行了对齐, 每一列表示一个像素颜色, 已经在注释标明. 生成的是一个8块颜色的彩条图 只需要给对应的像素点的rgb赋上对应的值, 就能生成对应的彩条图啦. 原理十分的简单. 效果图: 像素 640x360 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/video/h264/":{"url":"docs/video/h264/","title":"H264","keywords":"","body":"h264相关 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/video/h264/h264.html":{"url":"docs/video/h264/h264.html","title":"h264视频码流解析","keywords":"","body":"h264视频码流解析h264视频码流解析 H.264 原始码流(又称为裸流), 是一个接一个的NALU组成的, 而它的功能分为两层: 视频编码层(VCL)和网络提取层(NAL). VCL数据即编码处理的输出, 它表示被压缩编码后的视频数据序列. 在VCL数据传输或存储之前, 这些编码的VCL数据, 先被影射或封装进NAL单元(NALU)中. 每个NALU包括一个原始字节序列符合(RBSP)、一组对应于视频编码的NALU头部信息. NALU +------+ +-------+------+ | NALU |--->| NAL头 | RBSP | +------+ +-------+------+ NAL单元排列 NAL单元排列 +-------+------+-------+------+-------+------+ ... ... | NAL头 | RBSP | NAL头 | RBSP | NAL头 | RBSP | ... ... +-------+------+-------+------+-------+------+ 每个NALU之间通过startCode(起始码)进行分隔, 起始码分为两种: 0x000001(3bytes) 或者 0x00000001(4bytes). 如果NALU对应的slice为一帧的开始, 就用0x00000001, 否则就用0x000001. NALU头由一个字节组成: +---+---+---+---+---+---+---+---+ | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | +---+---+---+---+---+---+---+---+ | F | NRI | type | +---+-------+-------------------+ F: forbidden_zero_bit. 1个bit. 禁止位, 0表示正常, 1表示错误, 一般都为0. NRI: nal_ref_idc. 2个bit. 二进制取值 00~11, 表示这个NALU的重要性, 值越大越重要. type: nal_unit_type. 5个bit, 其各个值含义如下: +---------------+---------------------------+-------+ | nal_unit_type | NALU类型 | C | +---------------+---------------------------+-------+ | 0 | 未使用 | | +---------------+---------------------------+-------+ | 1 | 不分区, 非IDR的片 | 2,3,4 | +---------------+---------------------------+-------+ | 2 | 片分区A | 2 | +---------------+---------------------------+-------+ | 3 | 片分区B | 3 | +---------------+---------------------------+-------+ | 4 | 片分区C | 4 | +---------------+---------------------------+-------+ | 5 | IDR图像中的片 | 2,3 | +---------------+---------------------------+-------+ | 6 | 补充增强信息单元(SEI) | 5 | +---------------+---------------------------+-------+ | 7 | 序列参数集 | 0 | +---------------+---------------------------+-------+ | 8 | 图像参数集 | 1 | +---------------+---------------------------+-------+ | 9 | 分解符 | 6 | +---------------+---------------------------+-------+ | 10 | 序列结束 | 7 | +---------------+---------------------------+-------+ | 11 | 码流结束 | 8 | +---------------+---------------------------+-------+ | 12 | 填充 | 9 | +---------------+---------------------------+-------+ | 13-23 | 保留 | | +---------------+---------------------------+-------+ | 24-31 | 不保留 | | +---------------+---------------------------+-------+ H.264解析思路: 从码流中搜索起始码, 分离NALU; 然后再分析各个NALU头的字段. //*************************************************************** // @file: h264_parser.c // @author: dingfang // @date 2019-03-03 11:29:22 //*************************************************************** #include #include #include typedef enum { /* 0 未使用 */ NALU_TYPE_SLICE= 1,/* 不分区, 非IDR的片 */ NALU_TYPE_DPA= 2,/* 片分区A */ NALU_TYPE_DPB= 3,/* 片分区B */ NALU_TYPE_DPC= 4,/* 片分区C */ NALU_TYPE_IDR= 5,/* IDR图像中的片 */ NALU_TYPE_SEI= 6,/* 补充增强信息单元(SEI) */ NALU_TYPE_SPS= 7,/* 序列参数集 */ NALU_TYPE_PPS= 8,/* 图像参数集 */ NALU_TYPE_AUD= 9,/* 分解符 */ NALU_TYPE_EOSEQ= 10,/* 序列结束 */ NALU_TYPE_EOSTREAM= 11,/* 码流结束 */ NALU_TYPE_FILL= 12,/* 填充 */ /* 13-23 保留 */ /* 24-31 不保留 */ }NaluType_E; typedef enum { NALU_PRIORITY_DISPOSABLE= 0, NALU_PRIORITY_LOW= 1, NALU_PRIORITY_HIGH= 2, NALU_PRIORITY_HIGHEST= 3, }NaluPriority_E; typedef struct _T_NALU { intstartcodeprefixLen; unsigned int len; unsigned int maxSize; charforbiddenBit; charnalReferenceIdc; charnalUnitType; char*buf; }NALU_T; static int findStartCode3b(unsigned char *buf) { return (buf[2] != 1 || buf[0] !=0 || buf[1] != 0) ? 0 : 1;//0x000001 } static int findStartCode4b(unsigned char *buf) { return (buf[3] != 1 || buf[2] != 0 || buf[0] !=0 || buf[1] != 0) ? 0 : 1;//0x00000001 } int getAnnexbNalu(NALU_T *pNalu, FILE *fp) { unsigned char *buff = (unsigned char *)calloc(pNalu->maxSize, sizeof(char)); if (buff == NULL) { printf(\"buff calloc error !\\n\"); return -1; } int pos = 0; if (fread(buff, 1, 3, fp) != 3) { printf(\"fread len != 3\\n\"); free(buff); return -1; } if (findStartCode3b(buff) != 1) { if (fread(buff + 3, 1, 1, fp) != 1) { printf(\"fread len != 1\\n\"); free(buff); return -1; } if (findStartCode4b(buff) != 1) { free(buff); return -2; } else { pos = 4; pNalu->startcodeprefixLen = 4; } } else { pos = 3; pNalu->startcodeprefixLen = 3; } int rewind = 0; do { /* * 直到寻找到下一个起始码 * 在寻找到下一个startcode(起始码)之前的数据都是NALU * */ if (feof(fp)) { pNalu->len = (pos - 1) - pNalu->startcodeprefixLen; memcpy(pNalu->buf, &buff[pNalu->startcodeprefixLen], pNalu->len); pNalu->forbiddenBit= pNalu->buf[0] & 0x80; pNalu->nalReferenceIdc= pNalu->buf[0] & 0x60; pNalu->nalUnitType= pNalu->buf[0] & 0x1f; free(buff); buff = NULL; return pos - 1; } buff[pos++] = fgetc(fp); } while (!(1 == findStartCode4b(&buff[pos - 4]) || 1 == findStartCode3b(&buff[pos - 3]))); rewind = (1 == findStartCode4b(&buff[pos - 4])) ? -4 : -3; if (fseek(fp, rewind, SEEK_CUR) != 0) { free(buff); printf(\"getAnnexbNalu: fseek error\\n\"); } pNalu->len = (pos + rewind) - pNalu->startcodeprefixLen; memcpy(pNalu->buf, &buff[pNalu->startcodeprefixLen], pNalu->len); /* * forbiddenBit, nalReferenceIdc, nalUnitType共占1字节大小 * 0x80 1000 0000 * 0x60 0110 0000 * 0x1f 0001 1111 * */ pNalu->forbiddenBit= pNalu->buf[0] & 0x80; //1bit pNalu->nalReferenceIdc= pNalu->buf[0] & 0x60; //2bit pNalu->nalUnitType= pNalu->buf[0] & 0x1f; //5bit free(buff); return pos + rewind; } int h264_parser(const char *url) { //stdout//标准输出 //stdin//标准输入 //stderr//标准错误 FILE *myout = stdout; FILE *fp = fopen(url, \"rb+\"); if (fp == NULL) { printf(\"open h264 file error\\n\"); return -1; } NALU_T *pNalu = (NALU_T *)calloc(1, sizeof(NALU_T)); if (pNalu == NULL) { printf(\"pNalu calloc error\\n\"); fclose(fp); return -1; } int buffersize = 100000; pNalu->maxSize = buffersize; pNalu->buf = (char *)calloc(buffersize, sizeof(char)); if (pNalu->buf == NULL) { printf(\"pNalu->buf calloc error !\\n\"); free(pNalu); fclose(fp); return -1; } int dataOffset = 0; int nalNum = 0; printf(\"-----+---------+-- NALU Table --+---------+---------+\\n\"); printf(\" NUM | POS | IDC | TYPE | LEN | DATALEN |\\n\"); printf(\"-----+---------+--------+-------+---------+---------+\\n\"); while (!feof(fp)) { int dataLenth = getAnnexbNalu(pNalu, fp); if (dataLenth nalUnitType) { case NALU_TYPE_SLICE:sprintf(typeStr, \"SLICE\");break; case NALU_TYPE_DPA:sprintf(typeStr, \"DPA\");break; case NALU_TYPE_DPB:sprintf(typeStr, \"DPB\");break; case NALU_TYPE_DPC:sprintf(typeStr, \"DPC\");break; case NALU_TYPE_IDR:sprintf(typeStr, \"IDR\");break; case NALU_TYPE_SEI:sprintf(typeStr, \"SEI\");break; case NALU_TYPE_SPS:sprintf(typeStr, \"SPS\");break; case NALU_TYPE_PPS:sprintf(typeStr, \"PPS\");break; case NALU_TYPE_AUD:sprintf(typeStr, \"AUD\");break; case NALU_TYPE_EOSEQ:sprintf(typeStr, \"EOSEQ\");break; case NALU_TYPE_EOSTREAM:sprintf(typeStr, \"EOSTREAM\");break; case NALU_TYPE_FILL:sprintf(typeStr, \"FILL\");break; } char idcStr[10] = { 0 }; switch (pNalu->nalReferenceIdc >> 5) { case NALU_PRIORITY_DISPOSABLE:sprintf(idcStr, \"DISPOS\");break; case NALU_PRIORITY_LOW:sprintf(idcStr, \"LOW\");break; case NALU_PRIORITY_HIGH:sprintf(idcStr, \"HIGH\");break; case NALU_PRIORITY_HIGHEST:sprintf(idcStr, \"HIGHEST\");break; } if (nalNum len, dataLenth); } dataOffset += dataLenth; ++nalNum; } if (pNalu) { if (pNalu->buf) { free(pNalu->buf); pNalu->buf = NULL; } free(pNalu); pNalu = NULL; } fclose(myout); fclose(fp); return 0; } int main(void) { h264_parser(\"./sintel.h264\"); return 0; } 运行结果 因为数据很多, 我只选择了打印前30组的数据. -----+---------+-- NALU Table --+---------+---------+ NUM | POS | IDC | TYPE | LEN | DATALEN | -----+---------+--------+-------+---------+---------+ 0| 0| HIGHEST| SPS| 25| 29| 1| 29| HIGHEST| PPS| 6| 10| 2| 39| DISPOS| SEI| 686| 689| 3| 728| HIGHEST| IDR| 14710| 14713| 4| 15441| HIGH| SLICE| 6575| 6579| 5| 22020| DISPOS| SLICE| 2084| 2088| 6| 24108| HIGH| SLICE| 6622| 6626| 7| 30734| DISPOS| SLICE| 2216| 2220| 8| 32954| HIGH| SLICE| 6490| 6494| 9| 39448| DISPOS| SLICE| 2124| 2128| 10| 41576| HIGH| SLICE| 6662| 6666| 11| 48242| DISPOS| SLICE| 2221| 2225| 12| 50467| HIGH| SLICE| 5894| 5898| 13| 56365| DISPOS| SLICE| 2049| 2053| 14| 58418| HIGH| SLICE| 5085| 5089| 15| 63507| HIGH| SLICE| 7189| 7193| 16| 70700| DISPOS| SLICE| 2422| 2426| 17| 73126| HIGH| SLICE| 6953| 6957| 18| 80083| DISPOS| SLICE| 2561| 2565| 19| 82648| HIGH| SLICE| 6689| 6693| 20| 89341| DISPOS| SLICE| 2197| 2201| 21| 91542| HIGH| SLICE| 6307| 6311| 22| 97853| DISPOS| SLICE| 1972| 1976| 23| 99829| HIGH| SLICE| 6841| 6845| 24| 106674| DISPOS| SLICE| 1986| 1990| 25| 108664| HIGH| SLICE| 5435| 5439| 26| 114103| HIGH| SLICE| 354| 358| 27| 114461| HIGH| SLICE| 6183| 6187| 28| 120648| DISPOS| SLICE| 2381| 2385| 29| 123033| HIGH| SLICE| 5873| 5877| NUM为编号, POS为h264文件 NALU头+RBSP 数据的长度 pos大小为从第一个开始累加的. IDC就是NALU头的NRI, TYPE就是NALU头的type, LEN是一片数据的长度, DATALEN是LEN + 起始码长度. 以16进制查看程序解析的h264文件 这是该文件的开头部分数据. 黄色框内的是起始码, 白色框内的是NUAL头, 第一个白色框数值是0x67,即对应二进制0x0110 0111,由NUAL头结构分析可知, 禁止位为0, 重要性为11, type为7即表示序列参数集, 第一个白色框到第二个黄色框前的数据为RBSP数据. Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/video/flv/":{"url":"docs/video/flv/","title":"FLV","keywords":"","body":"flv相关 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/video/flv/flv.html":{"url":"docs/video/flv/flv.html","title":"flv封装格式解析","keywords":"","body":"flv封装格式解析flv封装格式解析 百度百科FLV是FLASHVIDEO的简称，FLV流媒体格式是一种新的视频格式，全称为FlashVideo。由于它形成的文件极小、加载速度极快，使得网络观看视频文件成为可能，它的出现有效地解决了视频文件导入Flash后，使导出的SWF文件体积庞大，不能在网络上很好的使用等缺点。除了FLV视频格式本身占有率低、体积小等特点适合网络发展外，丰富、多样的资源也是FLV视频格式统一在线播放视频格式的一个重要因素。现各视频网站大多使用的是FLV格式 flv结构 +-----------------+--------------------+-----------+ | | F | 8bits | | +--------------------+-----------+ | | L | 8bits | | +--------------------+-----------+ | | V | 8bits | | +--------------------+-----------+ | | version | 8bits | | +--------------------+-----------+ | header | typeFlagsReserved | 5bits | | +--------------------+-----------+ | | typeFlagsAudio | 1bit | | +--------------------+-----------+ | | typeFlagsReserved | 1bit | | +--------------------+-----------+ | | typeFlagsVideo | 1bit | | +--------------------+-----------+ | | DataOffset | 32bits | +-----------+-----+--------------------+-----------+ | | previousTagSize | 32bits | | +------+--------------------+-----------+ | | | tagType | 8bits | | | +--------------------+-----------+ | | | dataSize | 24bits | | | +--------------------+-----------+ | | | timestamp | 24bits | | | tag1 +--------------------+-----------+ | | | timestampExtended | 8bits | | | +--------------------+-----------+ | body | | streamID | 24bits | | | +--------------------+-----------+ | | | data | | | +------+--------------------+-----------+ | | previousTagSize | 32bits | | +------+--------------------+-----------+ | | tag2 | ... ... | ... ... | | +------+--------------------+-----------+ | | previousTagSize | 32bits | | +------+--------------------+-----------+ | | ... ... ... | | +------+--------------------+-----------+ | | tagn | ... ... | ... ... | | +------+--------------------+-----------+ | | previousTagSize | 32bits | +----------+------+--------------------+-----------+ flv由一个header和一个body组成, 其中body由多个previousTagSize和tag组成. header 前3个字节是固定的'FLV'作为标识 version占1个字节, 表示flv的版本号 flags占1个字节, 第0位和第2位分别表示video和audio(1表示存在, 0表示不存在)(例如两个都存在时为 0000 0101, 表示即有视频又有音频) DataOffset占4个字节, 表示FLV的header的长度, 通常看到的是固定的9 body previousTagSize固定4个字节, 表示前一个tag的size. tag分为三种类型: video, audio, scripts. tagType: 1byte 8表示audio, 9表示video, 18表示scripts dataSize: 3bytes 表示data的长度 timestamp: 3bytes 时间戳 timestampEx: 1byte 时间戳扩展字段 streamID: 3bytes 总是0 data: 数据部分 data数据部分与tagType对应. tagType表示audio时: data的首字节表示audio的参数信息: tagType是音频信息 data的第一个字节 +-------------+-------+-----+--------------------------------+ | | | 0 | Linear PCM, platform endian | | | +-----+--------------------------------+ | | | 1 | ADPCM | | | +-----+--------------------------------+ | | | 2 | MP3 | | | +-----+--------------------------------+ | | | 3 | Linear PCM, little endian | | | +-----+--------------------------------+ | | | 4 | Nellymoser 16-kHz mono | | | +-----+--------------------------------+ | | | 5 | Nellymoser 8-kHz mono | | | +-----+--------------------------------+ | | | 6 | Nellymoser | | | +-----+--------------------------------+ | 音频格式 | 4bits | 7 | G.711 A-law logarithmic PCM | | | +-----+--------------------------------+ | | | 8 | G.711 mu-law logarithmic PCM | | | +-----+--------------------------------+ | | | 9 | reserved | | | +-----+--------------------------------+ | | | 10 | AAC | | | +-----+--------------------------------+ | | | 11 | Speex | | | +-----+--------------------------------+ | | | 14 | MP3 8-kHz | | | +-----+--------------------------------+ | | | 15 | Device-specific sound | +-------------+-------+-----+--------------------------------+ | | | 0 | 6.6-kHz | | | +-----+--------------------------------+ | | | 1 | 11-kHz | | | +-----+--------------------------------+ | 采样率 | 2bits | 2 | 22-kHz | | | +-----+--------------------------------+ | | | 3 | 44-kHz | | | | | (对于AAC总是3) | +-------------+-------+-----+--------------------------------+ | | | 0 | snd8Bit | | | +-----+--------------------------------+ | 采样长度 | 1bit | 1 | snd16Bit | | | | | (压缩过的音频都是16bit) | +-------------+-------+-----+--------------------------------+ | | | 0 | sndMono | | | +-----+--------------------------------+ | 音频类型 | 1bit | 1 | sndStereo | | | | | (对于AAC总是1) | +-------------+-------+-----+--------------------------------+ tagType表示video时: data的首字节表示video的参数信息: tagType是视频信息 data的第一个字节 +-------------+-------+-----+---------------------------------------------------+ | | | 1 | keyframe (for AVC, a seekable frame) | | | +-----+---------------------------------------------------+ | | | 2 | inter frame (for AVC, a non-seekable frame) | | | +-----+---------------------------------------------------+ | 帧类型 | 4bits | 3 | disposable inter frame (H.253 only) | | | +-----+---------------------------------------------------+ | | | 4 | generated keyframe (reserved for server use only) | | | +-----+---------------------------------------------------+ | | | 5 | video info/command frame | +-------------+-------+-----+---------------------------------------------------+ | | | 1 | JPEG (currently unused) | | | +-----+---------------------------------------------------+ | | | 2 | Sorenson H.263 | | | +-----+---------------------------------------------------+ | 编码ID | 4bits | 3 | Screen video | | | +-----+---------------------------------------------------+ | | | 4 | On2 VP6 | | | +-----+---------------------------------------------------+ | | | 5 | On2 VP6 with alpha channel | | | +-----+---------------------------------------------------+ | | | 6 | Screen video version 2 | | | +-----+---------------------------------------------------+ | | | 7 | AVC | +-------------+-------+-----+---------------------------------------------------+ tagType表示scripts时: script 会放一些关于FLV视频和音频的元数据信息, 该类型通常放在FLV Header后面作为第一个tag出现, 而且只有一个. 第一个AMF包： 第1个字节表示AMF包类型，一般总是0x02，表示字符串。第2-3个字节为UI16类型值，标识字符串的长度，一般总是0x000A（“onMetaData”长度）。后面字节为具体的字符串，一般总为“onMetaData”（6F,6E,4D,65,74,61,44,61,74,61）。 第二个AMF包： 第1个字节表示AMF包类型，一般总是0x08，表示数组。第2-5个字节为UI32类型值，表示数组元素的个数。后面即为各数组元素的封装，数组元素为元素名称和值组成的对 常见的元数据信息: tagType是脚本信息 该类型的tag通常被称为Metadata Tag data的第一个字节 常见的MetaData +-----------------+----------------+ | 值 | 含义 | +-----------------+----------------+ | duration | 时长 | +-----------------+----------------+ | width | 视频宽度 | +-----------------+----------------+ | height | 视频高度 | +-----------------+----------------+ | videodatarate | 视频码率 | +-----------------+----------------+ | framerate | 视频帧率 | +-----------------+----------------+ | videocodecid | 视频编码方式 | +-----------------+----------------+ | audiosamplerate | 音频采样率 | +-----------------+----------------+ | audiosamplesize | 音频采样精度 | +-----------------+----------------+ | stereo | 是否为立体声 | +-----------------+----------------+ | audiocodecid | 音频编码方式 | +-----------------+----------------+ | filesize | 文件大小 | +-----------------+----------------+ 知道flv的结构, 就能够解析flv格式的文件了. 首先找到flv的Header, 由Header知道flv都包含的数据类型, 然后从第一个tag数据开始解析, 从tag信息中知道tag的类型, data的长度, 就可以计算出第一个tag结束位置和第二个tag开始的位置.最后就可以顺利的解析完FLV文件啦. //*************************************************************** // @file: flvParser.c // @author: dingfang // @date 2019-03-06 13:54:02 //*************************************************************** #include #include #include #pragma pack(1) #define TAG_TYPE_AUDIO 8 #define TAG_TYPE_VIDEO 9 #define TAG_TYPE_SCRIPT 18 typedef unsigned int uint32_t; typedef struct _T_FLV_HEADER { char signature[3]; char version; char flags; uint32_t dataOffset; }FLV_HEADER_T; typedef struct _T_TAG_HEADER { char tagType; char dataSize[3]; char timestamp[3]; char timestampEx; char reserved[3]; }TAG_HEADER_T; /* * 函数说明: 大端转小端 * 参数: p 需要转换的字符串 * c 转换的字节数 * */ uint32_t reverseChar(unsigned char *p, int c) {/* 大端转小端 */ int r = 0; for (int i = 0; i > 4; char audioTagStr[100] = { 0 }; strcat(audioTagStr, \"| \"); switch (format) { case 0: strcat(audioTagStr, \"Linear PCM, platform endian\"); break; case 1: strcat(audioTagStr, \"ADPCM\"); break; case 2: strcat(audioTagStr, \"MP3\"); break; case 3: strcat(audioTagStr, \"Linear PCM, little endian\"); break; case 4: strcat(audioTagStr, \"Nellymoser 16-kHz mono\"); break; case 5: strcat(audioTagStr, \"Nellymoser 8-kHz mono\"); break; case 6: strcat(audioTagStr, \"Nellymoser\"); break; case 7: strcat(audioTagStr, \"G.711 A-law logarithmic PCM\"); break; case 8: strcat(audioTagStr, \"G.711 mu-law logarithmic PCM\");break; case 9: strcat(audioTagStr, \"reserved\"); break; case 10: strcat(audioTagStr, \"AAC\"); break; case 11: strcat(audioTagStr, \"Speex\"); break; case 14: strcat(audioTagStr, \"MP3 8-Khz\"); break; case 15: strcat(audioTagStr, \"Device-specific sound\"); break; default: strcat(audioTagStr, \"unknown\"); break; } strcat(audioTagStr, \"| \"); int samplingRate = (tagDataFirstByte & 0x0C) >> 2; switch (samplingRate) { case 0: strcat(audioTagStr, \"5.5-kHz\"); break; case 1: strcat(audioTagStr, \"11-kHz\"); break; case 2: strcat(audioTagStr, \"22-kHz\"); break; case 3: strcat(audioTagStr, \"44-kHz\"); break; default: strcat(audioTagStr, \"unknown\");break; } strcat(audioTagStr, \"| \"); int accuracy = (tagDataFirstByte & 0x02) >> 1; switch (accuracy) { case 0: strcat(audioTagStr, \"snd8bit\"); break; case 1: strcat(audioTagStr, \"snd16bit\");break; default: strcat(audioTagStr, \"unknown\");break; } strcat(audioTagStr, \"| \"); int audioType = tagDataFirstByte & 0x01; switch (audioType) { case 0: strcat(audioTagStr, \"sndMono\"); break; case 1: strcat(audioTagStr, \"sndStereo\");break; default: strcat(audioTagStr, \"unknown\");break; } fprintf(myout, \"%s\", audioTagStr); uint32_t dataSize = reverseChar((unsigned char *)pTagHeader->dataSize, sizeof(pTagHeader->dataSize)) - 1; for (int i = 0; i > 4; switch (frameType) { case 1: strcat(videoTagStr, \"key frame\"); break; case 2: strcat(videoTagStr, \"inter frame\"); break; case 3: strcat(videoTagStr, \"disposable inter frame\"); break; case 4: strcat(videoTagStr, \"generated keyframe\"); break; case 5: strcat(videoTagStr, \"video info/command frame\");break; default: strcat(videoTagStr, \"unknown\"); break; } strcat(videoTagStr, \"| \"); int codeID = tagDataFirstByte & 0x0F; switch (codeID) { case 1: strcat(videoTagStr, \"JPEG\"); break; case 2: strcat(videoTagStr, \"Sorenson H.263\"); break; case 3: strcat(videoTagStr, \"Screen video\"); break; case 4: strcat(videoTagStr, \"On2 VP6\"); break; case 5: strcat(videoTagStr, \"On2 VP6 with alpha channel\"); break; case 6: strcat(videoTagStr, \"Screen video version 2\"); break; case 7: strcat(videoTagStr, \"AVC\"); break; default: strcat(videoTagStr, \"unknown\"); break; } fprintf(myout, \"%s\", videoTagStr); //因为保存的视频扔为flv格式 //把tagData的首字节留下 fseek(fp, -1, SEEK_CUR); //把最后一个preiousTagSize留下 uint32_t dataSize = reverseChar((unsigned char *)pTagHeader->dataSize, sizeof(pTagHeader->dataSize)) + 4; fwrite((char *)pTagHeader, 1, sizeof(TAG_HEADER_T), fp_v); for (int i = 0; i dataSize, sizeof(TAG_HEADER_T)), SEEK_CUR); return ; } /* * 函数说明: 解析flv文件 * 参数: url flv文件的url * */ int flvParser(const char *url) { FILE *fp = fopen(url, \"rb+\"); if (fp == NULL) { printf(\"flv file open error!\\n\"); return -1; } FILE *fp_v = fopen(\"./video.flv\", \"wb+\"); FILE *fp_a = fopen(\"./audio.mp3\", \"wb+\"); FILE *myout = stdout; FLV_HEADER_T flvHeader; TAG_HEADER_T tagHeader; uint32_t previousTagSize = 0; unsigned char *pData = (unsigned char *)malloc(1024 * 1024); fread(&flvHeader, 1, sizeof(flvHeader), fp); fprintf(myout, \"--------->FLV HeaderFLV End 30) { break; } fread(&previousTagSize, 1, 4, fp); memset(&tagHeader, 0, sizeof(TAG_HEADER_T)); fread((void *)&tagHeader, 1, sizeof(TAG_HEADER_T), fp); if (feof(fp)) { break; } uint32_t tagHeaderDataSize = reverseChar((unsigned char *)tagHeader.dataSize, 3); uint32_t tagHeaderTimeStamp = reverseChar((unsigned char *)tagHeader.timestamp, 3); char tagType[10] = { 0 }; switch (tagHeader.tagType) { case TAG_TYPE_AUDIO: sprintf(tagType, \"AUDIO\"); break; case TAG_TYPE_VIDEO: sprintf(tagType, \"VIDEO\"); break; case TAG_TYPE_SCRIPT: sprintf(tagType, \"SCRIPT\"); break; default: sprintf(tagType, \"unknown tagType\"); break; } fprintf(myout, \"[%6s] %6u %6u |\", tagType, tagHeaderDataSize, tagHeaderTimeStamp); switch (tagHeader.tagType) { case TAG_TYPE_AUDIO: processAudio(fp, myout, fp_a, &tagHeader); break; case TAG_TYPE_VIDEO: processVideo(fp, myout, fp_v, &tagHeader); break; case TAG_TYPE_SCRIPT: processScript(fp, myout, &tagHeader); break; default: fprintf(myout, \"unknow!----\"); break; } fprintf(myout, \"\\n\"); } return 0; } int main(void) { flvParser(\"./cuc_ieschool.flv\"); return 0; } 程序把音频和视频分离出来, 生成两个文件, 视频文件扔是flv格式, 生成的音频是mp3格式. --------->FLV HeaderFLV End最左边一列是tagType的类型, 第二列是data的长度, 第三列是时间戳(用于排列视频音频播放顺序), 第四列是音频格式或视频帧类型, 后面就是对应的音频采样率 采样精度 音频类型 或 视频编码ID. Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/audio/pcm/":{"url":"docs/audio/pcm/","title":"PCM","keywords":"","body":"音频相关 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/audio/pcm/pcm.html":{"url":"docs/audio/pcm/pcm.html","title":"pcm音频采样数据处理","keywords":"","body":"pcm音频采样数据处理音频处理分离左右声道降低音量加快速度pcm16le转换pcm8数据截取pcm16转wavepcm音频采样数据处理 41.1k_pcm16le 波形图, 声音时长22s 音频处理 分离左右声道 pcm16le双声道音频数据, 每4个字节为一个采样, 前两个字节为左声道, 后面两个字节为右声道. 以此可以很容易分离左声道右声道数据. //*************************************************************** // @file: pcm16le_split.c // @author: dingfang // @date 2019-03-01 10:15:46 //*************************************************************** #include #include /* * 函数说明: 分离pcm16le双声道音频采样数据的左声道和右声道 * 参数 url pcm16le数据的url * */ int pcm16le_split(const char *url) { FILE *fp = fopen(url, \"rb+\"); if (fp == NULL) { printf(\"打开音频文件失败\\n\"); return -1; } FILE *fp_l = fopen(\"./pcm16le_L.pcm\", \"wb+\"); FILE *fp_r = fopen(\"./pcm16le_R.pcm\", \"wb+\"); unsigned char *sample = (unsigned char *)malloc(4); while (!feof(fp)) { fread(sample, 1, 4, fp); //L fwrite(sample, 1, 2, fp_l); //R fwrite(sample + 2, 1, 2, fp_r); } free(sample); sample = NULL; fclose(fp); fclose(fp_l); fclose(fp_r); return 0; } int main(void) { pcm16le_split(\"./44.1k_s16le.pcm\"); return 0; } 分离后波形图 左声道: 声音时长22s 右声道: 声音时长22s 降低音量 将pcm16le双声道音频数据中的左声道音量降低一半 只需对左声道数据的值除以2就可以使得音量减半. //*************************************************************** // @file: pcm16le_halfvolumeleft.c // @author: dingfang // @date 2019-03-01 11:24:23 //*************************************************************** #include #include /* * 函数说明: 将pcm16le双声道音频数据左声道的音量降一半 * 参数 url pcm16le数据的url * */ int halfvolumeleft(const char *url) { FILE *fp = fopen(url, \"rb+\"); if (fp == NULL) { printf(\"pcm16le数据文件打开失败\\n\"); return -1; } FILE *fp_out = fopen(\"./44.1k_s16le_halfvolumeleft.pcm\", \"wb+\"); unsigned char *sample = (unsigned char *)malloc(4); while (!feof(fp)) { short *sampleNum = NULL; fread(sample, 1, 4, fp); sampleNum = (short *)sample; *sampleNum /= 2; //L fwrite(sample, 1, 2, fp_out); //R fwrite(sample + 2, 1, 2, fp_out); } free(sample); sample = NULL; fclose(fp); fclose(fp_out); return 0; } int main(void) { halfvolumeleft(\"./44.1k_s16le.pcm\"); return 0; } 处理后波形图 可以明显的看到左声道的幅度比原波形图要降低了很多. 加快速度 将pcm16le双声道音频数据的声音速度提高一倍 把原数据的采样以奇数(或者偶数)去掉一半, 播放的时候依旧按照44100hz进行播放. 这样就能达到播放速度提升一倍的效果. //*************************************************************** // @file: pcm16le_doublespeed.c // @author: dingfang // @date 2019-03-01 13:37:33 //*************************************************************** #include #include /* * 函数说明: 将pcm16le双声道音频数据的声音速度提高一倍 * 参数: url pcm16le数据的url * */ int pcm16le_doublespeed(const char *url) { FILE *fp = fopen(url, \"rb+\"); if (fp == NULL) { printf(\"pcm16le数据文件打开失败!\\n\"); return -1; } FILE *fp_out = fopen(\"./44.1k_pcm16le_doublespeed.pcm\", \"wb+\"); unsigned char *sample = (unsigned char *)malloc(4); int cnt = 0; while (!feof(fp)) { fread(sample, 1, 4, fp); if (cnt++ % 2 == 0) { fwrite(sample, 1, 4, fp_out); } } printf(\"cnt : %d\\n\", cnt); free(sample); sample = NULL; fclose(fp); fclose(fp_out); return 0; } int main(void) { pcm16le_doublespeed(\"./44.1k_s16le.pcm\"); return 0; } 处理后波形图 pcm16le转换pcm8 将pcm16le双声道音频数据转换为pcm8音频数据 pcm16le是2个字节存储一个单通道采样, pcm8是1个字节存储一个单通道采样, pcm16le-->pcm8 只需把pcm16le的高位8位赋值给pcm8就可以达到转换的效果. //*************************************************************** // @file: pcm16le_to_pcm8.c // @author: dingfang // @date 2019-03-01 14:11:57 //*************************************************************** #include #include /* * 函数说明: 将pcm16le双声道音频数据转换成pcm8音频数据 * 参数 url pcm16le数据文件url * */ int pcm16le_to_pcm8(const char *url) { FILE *fp = fopen(url, \"rb+\"); if (fp == NULL) { printf(\"pcm16le数据文件打开失败!\\n\"); return -1; } FILE *fp_out = fopen(\"./pcm8.pcm\", \"wb+\"); unsigned char *sample = (unsigned char *)malloc(4); while (fread(sample, 1, 4, fp) != 0) { short *sampleNum16 = NULL; char sampleNum8 = 0; unsigned char sampleUNum8 = 0; sampleNum16 = (short *)sample; for (int i = 0; i > 8; //sampleUNum8 = sampleNum8 + 128; //fwrite(&sampleUNum8, 1, 1, fp_out); fwrite(&sampleNum8, 1, 1, fp_out); } } free(sample); sample = NULL; fclose(fp); fclose(fp_out); return 0; } int main(void) { pcm16le_to_pcm8(\"./44.1k_s16le.pcm\"); return 0; } 转换后波形图 数据截取 从pcm16le单声道音频数据中截取一部分数据 从某个字节开始, 截取指定的长度, 把截取的数据写入新的音频文件. 很像截取字符串. 该操作也是很简单的. //*************************************************************** // @file: pcm16le_cut_singlechannel.c // @author: dingfang // @date 2019-03-01 16:17:58 //*************************************************************** #include #include /* * 函数说明: 从pcm16le单声道数据中截取一部分数据 * 参数 url pcm16le数据的url * start_num 开始位置 * dur_len 截取长度 * */ int pcm16le_cut_singlechannel(const char *url, int start_num, int dur_len) { FILE *fp = fopen(url, \"rb+\"); if (fp == NULL) { printf(\"pcm16数据文件打开失败!\\n\"); return -1; } FILE *fp_out = fopen(\"./drum_cut.pcm\", \"wb+\"); unsigned char *sample = (unsigned char *)malloc(2); int cnt = 0; while (fread(sample, 1, 2, fp) != 0) { if (cnt >= start_num && cnt 效果波形图 原音频波形图 截取后的音频波形图 pcm16转wave 将pcm16le双声道音频数据转换为wave格式的音频数据 wave数据结构: WAVE_HEADER + WAVE_FMT + WAVE_DATA + pcm 数据 了解了wave的数据结构, 就可以很轻松的拼装起来啦. //*************************************************************** // @file: pcm16le_to_wave.c // @author: dingfang // @date 2019-03-01 16:39:21 //*************************************************************** #include #include #include typedef struct _T_WAVE_HEADER { char fccID[4]; unsigned int dwSize; char fccType[4]; }WAVE_HEADER_T; typedef struct _T_WAVE_FMT { char fccID[4]; unsigned intdwSize; unsigned shortwFormatTag; unsigned shortwChannels; unsigned intdwSamplesPerSec; unsigned intdwAvgBytesPerSec; unsigned shortwBlockAlign; unsigned shortuiBitsPerSample; }WAVE_FMT_T; typedef struct _T_WAVE_DATA { char fccID[4]; unsigned int dwSize; }WAVE_DATA_T; /* * 函数说明: 把pcm16le双声道数据转换成wave格式的音频数据 * 参数 pcmUrl pcm16le数据的url * channels * sample_rate pcm采样率 * waveUrl wave音频数据url * */ int pcm16le_to_wave(const char *pcmUrl, int channels, int sample_rate, const char *waveUrl) { FILE *fp = fopen(pcmUrl, \"rb+\"); if (fp == NULL) { printf(\"pcm数据文件打开失败!\\n\"); return -1; } FILE *fp_wave = fopen(waveUrl, \"wb+\"); if (channels == 0 || sample_rate == 0) { channels = 2; sample_rate = 44100; } WAVE_HEADER_TwaveHeader= { 0 }; WAVE_FMT_TwaveFmt= { 0 }; WAVE_DATA_TwaveData= { 0 }; memcpy(waveHeader.fccID, \"RIFF\", strlen(\"RIFF\")); memcpy(waveHeader.fccType, \"WAVE\", strlen(\"WAVE\")); fseek(fp_wave, sizeof(WAVE_HEADER_T), 1); unsigned short pcmData; int bits = 16; waveFmt.dwSamplesPerSec= sample_rate; waveFmt.dwAvgBytesPerSec= waveFmt.dwSamplesPerSec * sizeof(pcmData); waveFmt.uiBitsPerSample = bits; memcpy(waveFmt.fccID, \"fmt \", strlen(\"fmt \")); waveFmt.dwSize = 16; waveFmt.wBlockAlign = 2; waveFmt.wChannels = channels; waveFmt.wFormatTag = 1; fwrite(&waveFmt, 1, sizeof(WAVE_FMT_T), fp_wave); memcpy(waveData.fccID, \"data\", strlen(\"data\")); waveData.dwSize = 0; fseek(fp_wave, sizeof(WAVE_DATA_T), SEEK_CUR); while (fread(&pcmData, 1, sizeof(unsigned short), fp) != 0) { waveData.dwSize += 2; fwrite(&pcmData, 1, sizeof(unsigned short), fp_wave); } waveHeader.dwSize = 44 + waveData.dwSize; rewind(fp_wave); fwrite(&waveHeader, 1, sizeof(WAVE_HEADER_T), fp_wave); fseek(fp_wave, sizeof(WAVE_FMT_T), SEEK_CUR); fwrite(&waveData, 1, sizeof(WAVE_DATA_T), fp_wave); fclose(fp); fclose(fp_wave); return 0; } int main(void) { pcm16le_to_wave(\"./44.1k_s16le.pcm\", 2, 44100, \"./pcm16le_to_wave.wav\"); return 0; } wave波形图 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/audio/aac/":{"url":"docs/audio/aac/","title":"AAC","keywords":"","body":"aac相关 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/audio/aac/aac.html":{"url":"docs/audio/aac/aac.html","title":"aac音频码流解析","keywords":"","body":"AAC音频码流解析AAC音频码流解析 首先了解一下AAC格式. AAC音频格式分析 AAC音频格式有ADIF和ADTS： ADIF：Audio Data Interchange Format 音频数据交换格式。这种格式的特征是可以确定的找到这个音频数据的开始，不需进行在音频数据流中间开始的解码，即它的解码必须在明确定义的开始处进行。故这种格式常用在磁盘文件中。 ADTS：Audio Data Transport Stream 音频数据传输流。这种格式的特征是它是一个有同步字的比特流，解码可以在这个流中任何位置开始。它的特征类似于mp3数据流格式。 简单说，ADTS可以在任意帧解码，也就是说它每一帧都有头信息。ADIF只有一个统一的头, 所以必须得到所有的数据后解码. 且这两种的header的格式也是不同的，目前一般编码后的和抽取出的都是ADTS格式的音频流. ADTS帧结构: +--------+---------+ | header | body | +--------+---------+ ADTS帧首部结构: +----------------------------------------+------------+--------------------------------------------------------------------+ | 序号 | 域 | 长度(bits) | 说明 | +----------------------------------------+------------+--------------------------------------------------------------------+ | 1 | Syncword | 12 | all bits must be 1 | +----------------------------------------+------------+--------------------------------------------------------------------+ | 2 | MPEG version | 1 | 0 for MPEG-4, 1 for MPEG-2 | +----------------------------------------+------------+--------------------------------------------------------------------+ | 3 | Layer | 2 | always 0 | +----------------------------------------+------------+--------------------------------------------------------------------+ | 4 | Protection Absent | 1 | et to 1 if there is no CRC and 0 if there is CRC | +----------------------------------------+------------+--------------------------------------------------------------------+ | 5 | Profile | 2 | the MPEG-4 Audio Object Type minus 1 | +----------------------------------------+------------+--------------------------------------------------------------------+ | 6 | MPEG-4 Sampling Frequency Index | 4 | MPEG-4 Sampling Frequency Index (15 is forbidden) | +----------------------------------------+------------+--------------------------------------------------------------------+ | 7 | Private Stream | 1 | set to 0 when encoding, ignore when decoding | +----------------------------------------+------------+--------------------------------------------------------------------+ | 8 | MPEG-4 Channel Configuration | 3 | MPEG-4 Channel Configuration (in the case of 0, the | | | | | channel configuration is sent via an inband PCE) | +----------------------------------------+------------+--------------------------------------------------------------------+ | 9 | Originality | 1 | set to 0 when encoding, ignore when decoding | +----------------------------------------+------------+--------------------------------------------------------------------+ | 10 | Home | 1 | set to 0 when encoding, ignore when decoding | +----------------------------------------+------------+--------------------------------------------------------------------+ | 11 | Copyrighted Stream | 1 | set to 0 when encoding, ignore when decoding | +----------------------------------------+------------+--------------------------------------------------------------------+ | 12 | Copyrighted Start | 1 | set to 0 when encoding, ignore when decoding | +----------------------------------------+------------+--------------------------------------------------------------------+ | 13 | Frame Length | 13 | this value must include 7 or 9 bytes of header length: | | | | | FrameLength = (ProtectionAbsent == 1 ? 7 : 9) + size(AACFrame) | +----------------------------------------+------------+--------------------------------------------------------------------+ | 14 | Buffer Fullness | 11 | buffer fullness | +----------------------------------------+------------+--------------------------------------------------------------------+ | 15 | Number of AAC Frames | 2 | number of AAC frames (RDBs) in ADTS frame minus 1, | | | | | for maximum compatibility always use 1 AAC frame per ADTS frame | +----------------------------------------+------------+--------------------------------------------------------------------+ | 16 | CRC | 16 | CRC if protection absent is 0 | +----------------------------------------+------------+--------------------------------------------------------------------+ 序号5的profile是音频对象类型: 2bits +-----+---------+ | 0 | Main | +-----+---------+ | 1 | LC | +-----+---------+ | 2 | SSR | +-----+---------+ 序号6是采样频率: 4bits +-----+---------------+ | 0 | 96000Hz | +-----+---------------+ | 1 | 88200Hz | +-----+---------------+ | 2 | 64000Hz | +-----+---------------+ | 3 | 48000Hz | +-----+---------------+ | 4 | 44100Hz | +-----+---------------+ | 5 | 32000Hz | +-----+---------------+ | 6 | 24000Hz | +-----+---------------+ | 7 | 22000Hz | +-----+---------------+ | 8 | 16000Hz | +-----+---------------+ | 9 | 12000Hz | +-----+---------------+ | 10 | 11025Hz | +-----+---------------+ | 11 | 8000Hz | +-----+---------------+ | 12 | 7350Hz | +-----+---------------+ | 13 | reserved | +-----+---------------+ | 14 | reserved | +-----+---------------+ | 15 | | +-----+---------------+ 序号1的syncword是同步字, 固定格式, 0xFFF. AAC原始码流是由一个个的ADTS frame组成, 它们由syncword分隔. 只要能找到syncword, 就能很容易分离ADTS的首部各个字段. //*************************************************************** // @file: aacParser.c // @author: dingfang // @date 2019-03-05 09:10:34 //*************************************************************** #include #include #include int getADTSframe(const unsigned char *pBuffer, int buffSize, unsigned char *pData, int *pDataSize) { int size = 0; if (!pBuffer || !pData || !pDataSize) { printf(\"pBuffer == NULL || pData == NULL || pDataSize == NULL\\n\"); return -1; } while (1) { if (buffSize > 5; //第41~43bit break; } --buffSize; ++pBuffer; } if (buffSize >= 6; switch (profile) { case 0: sprintf(profileStr, \"Main\"); break; case 1: sprintf(profileStr, \"LC\"); break; case 2: sprintf(profileStr, \"SSR\"); break; default: sprintf(profileStr, \"unknown\"); break; } /* 第19~22bit 表示采样频率, 禁止15*/ unsigned char samplingFrequencyIndex = pAacFrame[2] & 0x3C; samplingFrequencyIndex >>= 2; switch (samplingFrequencyIndex) { case 0: sprintf(frequenceStr, \"96000Hz\"); break; case 1: sprintf(frequenceStr, \"88200Hz\"); break; case 2: sprintf(frequenceStr, \"64000Hz\"); break; case 3: sprintf(frequenceStr, \"48000Hz\"); break; case 4: sprintf(frequenceStr, \"44100Hz\"); break; case 5: sprintf(frequenceStr, \"32000Hz\"); break; case 6: sprintf(frequenceStr, \"24000Hz\"); break; case 7: sprintf(frequenceStr, \"22050Hz\"); break; case 8: sprintf(frequenceStr, \"16000Hz\"); break; case 9: sprintf(frequenceStr, \"12000Hz\"); break; case 10: sprintf(frequenceStr, \"11025Hz\"); break; case 11: sprintf(frequenceStr, \"8000Hz\"); break; default: sprintf(frequenceStr, \"unknown\"); break; } fprintf(myout, \"%5d| %8s| %8s| %5d|\\n\", cnt, profileStr, frequenceStr, size); dataSize -= size; inputData += size; if (cnt > 30) { return 2; } ++cnt; } } free(pAacBuffer); pAacBuffer = NULL; free(pAacFrame); pAacFrame = NULL; fclose(fp); return 0; } int main(void) { aacParser(\"./nocturne.aac\"); return 0; } 找到syncword后, 然后由ADTS格式, 可以根据每个bit表示的意义输出表示的值. -----+- ADTS Frame Table -+------+ NUM | Profile | Frequency| Size | -----+---------+----------+------+ 0| LC| 44100Hz| 371| 1| LC| 44100Hz| 372| 2| LC| 44100Hz| 371| 3| LC| 44100Hz| 372| 4| LC| 44100Hz| 371| 5| LC| 44100Hz| 372| 6| LC| 44100Hz| 371| 7| LC| 44100Hz| 372| 8| LC| 44100Hz| 371| 9| LC| 44100Hz| 372| 10| LC| 44100Hz| 371| 11| LC| 44100Hz| 372| 12| LC| 44100Hz| 371| 13| LC| 44100Hz| 372| 14| LC| 44100Hz| 371| 15| LC| 44100Hz| 372| 16| LC| 44100Hz| 371| 17| LC| 44100Hz| 372| 18| LC| 44100Hz| 371| 19| LC| 44100Hz| 372| 20| LC| 44100Hz| 371| 21| LC| 44100Hz| 372| 22| LC| 44100Hz| 371| 23| LC| 44100Hz| 372| 24| LC| 44100Hz| 371| 25| LC| 44100Hz| 372| 26| LC| 44100Hz| 372| 27| LC| 44100Hz| 371| 28| LC| 44100Hz| 372| 29| LC| 44100Hz| 371| 30| LC| 44100Hz| 372| 31| LC| 44100Hz| 371| Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/protocol/udp-rtp/":{"url":"docs/protocol/udp-rtp/","title":"udp-rtp","keywords":"","body":"协议相关 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/protocol/udp-rtp/udp-rtp.html":{"url":"docs/protocol/udp-rtp/udp-rtp.html","title":"udp-rtp协议解析","keywords":"","body":"udp-rtp协议udp-rtp协议 udp-rtp协议的结构 udp由udpHeader和udpBody组成. udpBody由rtpHeader和rtpBody组成 rtpBody由7个TS Pkt组成. rtpHeader的数据结构 RTP头结构 +------+--------+-----------------------------------------------------+ | V | 2bits | RTP协议的版本号 | +------+--------+-----------------------------------------------------+ | | | 填充标志, 如果p=1, 则在该报文的尾部填充一个或多个额 | | P | 1bit | 外的八位组, 它们不是有效载荷的一部分 | +------+--------+-----------------------------------------------------+ | X | 1bit | 扩展位置, 如果x=1, 则在RTP报头后跟一个扩展报头 | +------+--------+-----------------------------------------------------+ | CC | 4bits | CSRC计数器, 指示CSRC标识符的个数 | +------+--------+-----------------------------------------------------+ | M | 1bit | 标记, 对于视频:标记一帧的结束. 对于音频:标记会话开始| +------+--------+-----------------------------------------------------+ | | | 用于说明RTP报文中有效载荷的类型, 如GSM音频,JPEM图像 | | PT | 7bits | 等, 在流媒体中大部分是用来区分音频流和视频流的, 这样| | | | 便于客户端进行解析 | +------+--------+-----------------------------------------------------+ | | | 用于标识发送者所发送的RTP报文的序列号,每发送一个报 | | | | 文,序列号增1.这个字段当下层的承载协议用UDP的时候,网 | |序列号| 16bits | 络状况不好的时候可以用来检查丢包.同时出现网络抖动的 | | | | 情况可以用来对数据进行重新排序,序列号的初始值是随机 | | | | 的,同时音频包和视频包的sequence是分别记数的. | +------+--------+-----------------------------------------------------+ | | | 记录了该包中数据的第一个字节的采样时刻.在一次会话开 | |时间戳| 32bits | 始时,时间戳初始化成一个初始值.即使在没有信号发送时, | | | | 时间戳的数值也要随时间而不断地增加. | +------+--------+-----------------------------------------------------+ | | | 同步源就是指RTP包流的来源.在同一个RTP会话中不能有两 | |同步源| 32bits | 个相同的SSRC值.该标识符是随机选取的 RFC1889推荐了MD5| |标识符| | 随机算法 | +------+--------+-----------------------------------------------------+ 固定占用12个字节, 具体释义已经标记的很清楚了. 这次的例子是mpegTS, 所以它的头也了解一下, 不过没有对其头进行解析. 请看图(图片摘自网络): 由rtp的结构可以解析出其数据啦 //*************************************************************** // @file: udpParser.c // @author: dingfang // @date 2019-03-11 11:25:21 //*************************************************************** #include #include #include #include #include #include #include #include #include #include #include #include #pragma pack(1) #define INVALID_SOCKET (-1) #define RECV_DATA_SIZE 10240 typedef struct _T_RTP_FIXED_HEADER { /* byte0 */ unsigned char version: 2; unsigned char extensizon: 1; unsigned char padding: 1; unsigned char strLen: 4; /* byte 1 */ unsigned char payload: 7; unsigned char marker: 1; /* bytes 2, 3 */ unsigned short seqNo; /* bytes 4-7 */ unsigned int timestamp; /* bytes 8-11 */ unsigned int ssrc; }RTP_FIXED_HEADER_T; typedef struct _T_MpegTS_FIXED_HEADER { unsigned char syncType: 8; unsigned char transportErrorIndicator: 1; unsigned char payloadUnitStartIndicator: 1; unsigned char transportPriority: 1; unsigned PID: 13; unsigned scramblingControl: 2; unsigned adaptationFieldExist: 2; unsigned continuityCounter: 4; }MpegTS_FIXED_HEADER_T; void switchPayload(char payload, char *payloadStr) { switch (payload) { case 0: case 1: case 2: case 3: case 4: case 5: case 6: case 7: case 8: case 9: case 10: case 11: case 12: case 13: case 14: case 15: case 16: case 17: case 18: sprintf(payloadStr, \"Audio\"); return; case 31: sprintf(payloadStr, \"H.261\"); return; case 32: sprintf(payloadStr, \"MPV\"); return; case 33: sprintf(payloadStr, \"MP2T\"); return; case 34: sprintf(payloadStr, \"H.263\"); return; case 96: sprintf(payloadStr, \"H.264\"); return; default: sprintf(payloadStr, \"other\"); return; } } void mpegTSprocess(char *rtpData, int rtpDataSize, FILE *myout) { MpegTS_FIXED_HEADER_T mpegtsHeader; int i; for (i = 0; i 0) { char payloadStr[10] = { 0 }; RTP_FIXED_HEADER_T rtpHeader; int rtpHeaderSize = sizeof(RTP_FIXED_HEADER_T); memcpy((void *)&rtpHeader, recvData, rtpHeaderSize); char payload = rtpHeader.payload; switchPayload(payload, payloadStr); unsigned int timestamp = ntohl(rtpHeader.timestamp); unsigned int seqNo = ntohs(rtpHeader.seqNo); fprintf(myout, \"[RTP Pkt] %5d| %5s| %10u| %5d| %5d|\\n\", cnt, payloadStr, timestamp, seqNo, pktsize); char *rtpData = recvData + rtpHeaderSize; int rtpDataSize = pktsize - rtpHeaderSize; fwrite(rtpData, rtpDataSize, 1, fp); if (parseMpegTS != 0 && payload == 33) { mpegTSprocess(rtpData, rtpDataSize, myout); } if (cnt == 15) { break; } ++cnt; } } close(serSocket); fclose(fp); return 0; } int main(void) { udpParser(8877); return 0; } 通过udp编程可以直接获取到udp的Body, 再对body进行解析, 就能获取到对应的数据. 运行程序后等待客户端推流. 我是用的是VLC media player. 具体使用步骤: 首先点击左上角的媒体, 找到'流' 点进去. 点击添加按钮. 添加本地的ts文件. 添加完文件后, 点击下面的选择串流. 这个直接 点击下一个. 在这选择RTP / MPEG Transport Stream 在这里输入推流的地址和端口, 名字随意. 在这选择视频和音频格式, 我的应该选择这个, 如果你用的和我一样的文件, 那么也应该选择这个 输出结果 count就是每个包里面包含7个TS Pkt(代码里面可以看出) Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/ffmpeg/":{"url":"docs/ffmpeg/","title":"ffmpeg","keywords":"","body":"ffmpeg相关 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/ffmpeg/ffmpeg.html":{"url":"docs/ffmpeg/ffmpeg.html","title":"ffmpeg解码音视频过程","keywords":"","body":"ffmpeg解码音视频过程解码流程代码ffmpeg解码音视频过程 ffmpeg有两个重要的结构体 AVPacket 保存未解码的数据. AVFrame 保存解码后的数据. 解码流程 代码 //*************************************************************** // @file: test.c // @author: dingfang // @date 2019-07-24 18:55:16 //*************************************************************** #include #ifdef __cplusplus extern \"C\" { #endif #include #include #ifdef __cplusplus }; #endif int openCodecContext(const AVFormatContext *pFormatCtx, int *pStreamIndex, enum AVMediaType type, AVCodecContext **ppCodecCtx) { int streamIdx = -1; // 获取流下标 for (int i = 0; i nb_streams; i++) { if (pFormatCtx->streams[i]->codec->codec_type == type) { streamIdx = i; break; } } if (streamIdx == -1) { printf(\"find video stream failed!\\n\"); exit(-2); } // 寻找解码器 AVCodecContext *pCodecCtx = pFormatCtx->streams[streamIdx]->codec; AVCodec *pCodec = avcodec_find_decoder(pCodecCtx->codec_id); if (NULL == pCodec) { printf(\"avcode find decoder failed!\\n\"); exit(-2); } //打开解码器 if (avcodec_open2(pCodecCtx, pCodec, NULL) stream_index == videoStreamIdx) { avcodec_decode_video2(pVideoCodecCtx, pFrame, &ret, pPacket); if (ret == 0) { printf(\"video decodec error!\\n\"); continue; } printf(\"* * * * * * video * * * * * * * * *\\n\"); printf(\"___height: [%d]\\n\", pFrame->height); printf(\"____width: [%d]\\n\", pFrame->width); printf(\"pict_type: [%d]\\n\", pFrame->pict_type); printf(\"___format: [%d]\\n\", pFrame->format); printf(\"* * * * * * * * * * * * * * * * * * *\\n\\n\"); } /* 音频解码 */ if (pPacket->stream_index == audioStreamIdx) { avcodec_decode_audio4(pAudioCodecCtx, pFrame, &ret, pPacket); if (ret nb_samples); printf(\"__samples_rate: [%d]\\n\", pFrame->sample_rate); printf(\"channel_layout: [%lu]\\n\", pFrame->channel_layout); printf(\"________format: [%d]\\n\", pFrame->format); printf(\"* * * * * * * * * * * * * * * * * * *\\n\\n\"); } av_packet_unref(pPacket); } av_frame_free(&pFrame); av_packet_free(&pPacket); avcodec_close(pVideoCodecCtx); avcodec_close(pAudioCodecCtx); avformat_close_input(&pInFormatCtx); return 0; } 这里就几个比较重要的函数简单介绍一下. av_register_all() 　　　　　　 /* 使用ffmpeg几乎都要调用这一个函数, 注册ffmpeg各种编解码器, 复用器等. */ avformat_open_input() 　　　　/* 该函数用于打开本地多媒体文件或者网络流媒体url */ avformat_find_stream_info() /* 该函数用于读取一部分音视频数据并且获得一些相关的信息 */ avcodec_find_decoder()　　　　/* 由codec_id或者解码器名称来寻找对应的解码器 */ avcodec_open2()　　　　　　　 /* 初始化解码器 */ av_read_frame()　　　　　　　 /* 读流数据, 读出来的是压缩数据, 存放于AVPacket */ avcodec_decode_video2()　　　 /* 视频解码 解码后数据为原始数据, 存放于AVFrame */ avcodec_decode_audio4()　　　 /* 音频解码 解码后数据为原始数据, 存放于AVFrame */ Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "}}