{"./":{"url":"./","title":"前言","keywords":"","body":"简介参考简介 背景 在生活或工作中，总会有许许多多的问题，我想把这些遇到的问题记录下来，但不想和我的博客混到一起，博客是我写经验心得、教程和知识点的地方。所以我单独搞一个 什么为什么 的栏目，来搞这个问题记录。 特点 基本每篇都是以什么、为什么开头 每个篇幅都比较简短，主要围绕问题来描述 当我觉得可以把问题总结归纳成文章时，我会从这里删除掉，写入到博客 生成 这是使用 gitbook 生成的类似于电子书形式的页面，与我的博客一同部署 来这里找到答案吧 ！ 参考 部署参考 gitbook-notes GitBook使用教程 emoje表情代码 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/linux/fork.html":{"url":"docs/linux/fork.html","title":"为什么fork两次","keywords":"","body":"为什么fork两次为什么fork两次 你可能会在某些代码中看到fork两次，比如守护进程代码。但为什么要fork两次呢？ 原因 守护进程 fork 的第二次主要是为了防止再次打开一个控制终端。 但守护进程并没有fork两次的必要。 打开控制终端的前提条件是该进程必须是会话组长。再fork一次，子进程ID != sid。当然也无法打开新的控制终端 不过在打开终端设备时可以指定 O_NOCTTY 来避免打开控制终端，所以没必要 fork 两次 什么情况需要fork两次 一个进程fork一个子进程，但不想要等待子进程终止，也不希望子进程处于僵尸状态直到父进程终止，这时使用fork两次的技巧可以解决这个问题 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/linux/zero_copy.html":{"url":"docs/linux/zero_copy.html","title":"什么是零拷贝","keywords":"","body":"前言什么是零拷贝为什么用零拷贝怎么做到零拷贝前言 传统的 Linux 操作系统的标准 I/O 接口是基于数据拷贝操作的，即 I/O 操作会导致数据在操作系统内核地址空间的缓冲区和应用程序地址空间定义的缓冲区之间进行传输。这样做最大的好处是可以减少磁盘 I/O 的操作，因为如果所请求的数据已经存放在操作系统的高速缓冲存储器中，那么就不需要再进行实际的物理磁盘 I/O 操作。但是数据传输过程中的数据拷贝操作却导致了极大的 CPU 开销，限制了操作系统有效进行数据传输操作的能力。 什么是零拷贝 CPU 不需要先将数据从一个内存区域复制到另一个内存区域，从而可以减少上下文切换以及 CPU 的拷贝时间。 为什么用零拷贝 零拷贝技术可以减少数据拷贝和共享总线操作的次数，消除传输数据在存储器之间不必要的中间拷贝次数，从而有效地提高数据传输效率。 零拷贝技术减少了用户应用程序地址空间和操作系统内核地址空间之间因为上下文切换而带来的开销。 进行大量的数据拷贝操作其实是一件简单的任务，从操作系统的角度来说，如果 CPU 一直被占用着去执行这项简单的任务，那么这很浪费资源的；如果有其他比较简单的系统部件可以代劳这件事情，使得 CPU 解脱出来可以做别的事情，那么系统资源的利用会更加有效。 零拷贝技术目标 避免操作系统内核缓冲区之间进行数据拷贝操作。 避免操作系统内核和用户应用程序地址空间这两者之间进行数据拷贝操作。 用户应用程序可以避开操作系统直接访问硬件存储。 数据传输尽量让 DMA 来做。 避免不必要的系统调用和上下文切换。 需要拷贝的数据可以先被缓存起来。 对数据进行处理尽量让硬件来做。 将一个磁盘文件不做修改的通过socket发送出去 从图中可以看出, 一共进行了4次拷贝, 其中cpu进行了两次拷贝, 而且在内核态和用户态之间还会进行多次的上下文切换.这无疑增加了不少cpu负担, 这时用零拷贝技术, 可以有效提升效率并能提升cpu效率 怎么做到零拷贝 存储映射I/O 存储映射I/O(memory-mapped I/O)能将一个磁盘文件映射到存储空间中的一个缓存区上, 于是, 当从缓冲区中取数据时, 就相当于读文件中的相应的字节. 这时上面的磁盘文件发送到socket就变成了如下情况 用户空间的缓存与内核空间的缓存有个映射关系, 相当于用户共享了内核空间的内存, 用户空间往socket缓冲区拷贝数据, 就相当于从一个内核区域拷贝到另一个内核区域, 减少了cpu拷贝次数. mmap的缺点 当引用尚不存在的内存页时, 这样的复制过程就会作为处理页错误的结果而出现, 当这种页错误频繁出现时, 会大大影响效率. 该映射是需要页对齐的, 对小数据来映射, 会产生内存浪费和内存碎片 其它的零拷贝技术, 同样是以减少内核空间与用户空间之间的多余拷贝过程而达到零拷贝目标的, 只是有不同的应用场景和实现方式. 其它零拷贝方法 sendfile 数据可以直接在内核空间内部进行I/O传输, sendfile调用中I/O数据对用户空间是完全不可见的. splice splice系统调用可以在内核空间的读缓冲区和网络缓冲区之间建立管道, 从而避免两者之间的CPU拷贝操作 最后要知道, 零拷贝不是没有拷贝, 而是减少没必要的拷贝 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/linux/lock.html":{"url":"docs/linux/lock.html","title":"什么是建议性锁","keywords":"","body":"建议性锁和强制性锁建议性锁和强制性锁 强制性锁会让内核检查每一个open、read和write，验证调用进程是否违背了正在访问的文件上的某一把锁。 强制性锁也称为强迫方式锁 建议性锁不能阻止对数据库文件有写权限的任何其他进程写这个数据库文件。只能有程序员在写之前进行检查，获取状态，来判断是否有锁加持。 建议性锁需要自行判断锁状态，来自觉遵守锁规则。 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/linux/func_r.html":{"url":"docs/linux/func_r.html","title":"什么是可重入函数","keywords":"","body":"什么是可重入函数参考什么是可重入函数 可重入函数主要用于多任务环境中，一个可重入的函数简单来说就是可以被中断的函数，也就是说，可以在这个函数执行的任何时刻中断它，转入OS调度下去执行另外一段代码，而返回控制时不会出现什么错误；而不可重入的函数由于使用了一些系统资源，比如全局变量区，中断向量表等，所以它如果被中断的话，可能会出现问题，这类函数是不能运行在多任务环境下的。 在信号处理函数中尽量不要使用标准I/O函数，因为许多版本的标准I/O函数库是不可重入函数 参考 可重入函数百度百科 UNIX网络编程卷1 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/cpp/define.html":{"url":"docs/cpp/define.html","title":"为什么宏定义带有很多小括号","keywords":"","body":"为什么宏定义计算时要加小括号为什么宏定义计算时要加小括号 你可能会看到这样的代码 #define MULTIPLY(a, b) ((a) * (b)) 上面的a 和 b 被一层层的小括号包裹，有这个必要吗 ？ 答案是：有 看一下下面的代码 #include #define MULTIPLY(a, b) ((a) * (b)) int main(void) { printf(\"%d\\n\", MULTIPLY(3 + 2, 4) + 1); return 0; } 我们知道，宏定义在预处理时就是一个替换，把使用宏的地方替换成宏的真实代码 上面代码使用(假如代码写在test.c文件) gcc -E test.cpp 预处理后可以看到包含有如下代码 int main(void) { printf(\"%d\\n\", ((3 + 2) * (4)) + 1); return 0; } MULTIPLY(3 + 2, 4) 部分被替换成了 ((3 + 2) * (4))， 到这里就可以看出一些东西来了，如果没有小括号，那这个表达式就变成了 3 + 2 * 4 + 1， 这样的话，我们期望的结果就会与实际结果不同，导致程序出现bug 上面的代码还可以这样写 /* 没有使用小括号 */ #define MULTIPLY(a, b) a * b int main(void) { int m = 0; MULTIPLY(int, p); return 0; } 这个预处理之后被替换成了如下代码 int main(void) { int m = 0; int * p; return 0; } MULTIPLY(int, p) 变成了 int * p 这样的结果更会让使用者迷惑不已。 总结 通过上面的两个例子可以看出，宏定义的时候，特别是有计算时，一定要带上小括号， 不然就有可能发生不可预期的bug。 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/protocol/https.html":{"url":"docs/protocol/https.html","title":"为什么https是安全的","keywords":"","body":"HTTP协议为什么不安全HTTP中间人攻击HTTPS协议是如何做到安全的HTTPS保证安全的三个主要技术数字证书作用申请CA数字证书数字证书验证数据传输参考HTTP协议为什么不安全 HTTP中间人攻击 HTTP协议中的报文都是以明文的方式进行传输，不做任何加密。 正常客户端到服务端的流程如下 数据 C --------> S 如果此时有个中间人劫持了数据，那无疑泄露了数据 C ------>中间人------->S 那如果对发送到数据进行加密呢？ 对称加密 首先对数据如果进行对称加密，那肯定需要把密钥发送给服务端解密吧，如果发送密钥时被劫持，那跟明文发送并无两样。 公钥加密 这套密码算法包含配对的密钥对，分为加密密钥(公钥)和解密密钥(私钥)。客户端使用公钥进行加密，服务端使用私钥进行解密。 我要请求 C -------------> S 公钥下发 C S 这样即使中间人获取到数据，但没有私钥就无法解密。 可实际上客户端收到服务端的公钥，真的就是服务端下发的吗？ 我要请求 我要请求 C -------------> 中间人 ----------------> S 公钥下发(中间人伪造公钥) 公钥下发 C S 公钥加密数据 中间人修改后数据 C -------------> 中间人 ----------------> S 中间人在劫持到客户端发起的请求时，自己伪造一个公钥下发给客户端，客户端用这个伪造公钥加密的数据对中间人来说和明文无异 所以，HTTP不安全 HTTPS协议是如何做到安全的 HTTPS其实是 HTTP + SSL/TLS 的组合 HTTPS在传输数据之前需要客户端和服务端进行握手，在握手的过程中确立双方加密传输数据的密钥信息。SSL/TLS协议是一套加密传输协议，使用了非对称加密、对称加密以及HASH算法。 TLS是SSL协议的当前版本，以前称为SSL HTTPS保证安全的三个主要技术 证书验证 非对称加密传输对称加密key 数据对称加密传输 数字证书是由权威机构颁发用于将加密密钥对与诸如网站、个人或组织之类的实体相关联的一种文件类型 数字证书作用 身份授权 确保浏览器访问的网站是经过CA验证的可信任的网站 分发公钥 每个数字证书都包含了注册者生产的公钥。在SSL握手时通过certificate消息传输给客户端 验证证书合法性 客户端收到数字证书后，会对证书合法性进行验证。只有通过验证的证书，才能进行后续通信 申请CA数字证书 公司(实体)服务器生成公钥和私钥，以及CA数字证书请求 RA(证书注册和审核机构)检查实体店合法性 CA(证书签发机构)签发证书，发送给申请者实体 证书更新到repository(负责数字证书及CRL内容存储和分发)，实体终端后续从repository更新证书，查询证书状态等 权威机构与浏览器和操作系统都有合作，根证书公钥都默认装到了浏览器或操作系统环境里 数字证书验证 数字签名的签发 首先使用哈希算法对待签名内容进行哈希，生成消息摘要，然后使用CA的私钥对消息摘要进行加密 数值签名的校验 使用CA的公钥解密签名，然后使用相同的签名算法对签名证书内容进行签名，并和服务端数字签名里的签名内容进行比对，相同就认为校验成功 数据传输 当数字证书验证成功后，客户端就可以把本地随机生成的密钥通过服务端的公钥加密发送给服务端，接下来就可以使用密钥来放心进行对称加密数据传输了。 参考 HTTPS为什么更安全 为什么HTTPS是安全的 什么是数字证书 HTTPS与SSL证书概要 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/protocol/tcp.html":{"url":"docs/protocol/tcp.html","title":"为什么tcp需要握手三次和四次挥手","keywords":"","body":"tcp协议TCP状态描述三次握手四次挥手参考tcp协议 TCP状态描述 LISTEN TCP正等待从对端TCP节点发来的连接请求 SYN_SENT TCP发送一个SYN报文，代表应用程序执行了一个主动打开的操作，并等待对端回应以此完成连接建立 SYN_RECV 之前处于LISTEN状态的TCP节点收到了对端发送的SYN报文，并已经通过发送SYN/ACK报文做出了响应，正等待对端TCP节点发送一个ACK以此完成连接的建立 ESTABLISHED 与对端TCP节点间的连接建立完成。数据报文此时可以在两个TCP节点间双向交换 FIN_WAIT1 应用程序关闭了连接。TCP节点发送一个FIN报文到对端，以此终止本端的连接，并等待对端发送来的ACK。 FIN_WAIT2 之前处于FIN_WAIT1状态的TCP节点现在已经收到了对端的TCP节点发来的ACK CLOSEING 之前处于FIN_WAIT1状态的TCP节点正在等待对端发送ACK，但却收到了FIN。这表示对端也正在尝试执行一个主动关闭。 TIME_WAIT 完成主动关闭后，TCP节点收到了FIN报文。这表示对端执行了一个被动关闭。这时这个TCP节点将在TIME_WAIT状态中等待一段固定的时间，这是为了确保TCP连接能够可靠的终止，同时也是为了确保任何老的重复的报文在重新建立同样的连接之前在网络中超时消失。当这个固定的时间段超时后，连接就关闭了，相关的内核资源都得到释放 CLOSE_WAIT TCP节点从对端接收到FIN报文后将处于CLOSE_WAIT状态。 LAST_ACK 应用程序执行被动关闭，而之前处于CLOSE_WAIT状态的TCP节点发送到一个FIN报文给对端，并等待对端确认。当收到对端发来的确认ACK报文时，连接关闭，相关的内核资源都会得到释放 三次握手 三次握手状态转换图如下(比较粗略) Client Server +-------------+ +-------------+ | | | CLOSE | | CLOSE | +-------------+ | | SYN M | LISTEN | +-------------+ -----------------> +-------------| | | | | | | | | | SYN_SENT | | SYN_RECV | | | SYN N, ACK M+1 | | +-------------+ +-------------+ tcp是面向连接的通信，三次握手的作用就是双方都能明确自己和对方的收、发数据的能力是正常的，同时需要初始化seq序列号来做可靠重传或接收，而避免连接复用时无法分辨出seq是延迟或者是旧连接的seq 第一次握手，客户端发送SYN 服务端知道客户端有发送能力以及客户端序列号初始值，并且知道自己有接收能力 第二次握手，服务端发送一个SYN并包含ACK 客户端知道服务端有接收和发送到能力并知道服务端序列号初始值，并且知道自己有发送能力和接收能力 第三次握手，客户端回复ACK 服务端知道客户端有接收的能力，并且知道自己有发送能力 经过上面的三次握手过程，客户端和服务端都确认了自己和对方的接收、发送能力是正常的。然后就可以正常通信传输数据了。 两次或四次握手可以吗 两次握手必然会出现某种能力是处于未知状态的，无法建立可靠的通信 既然三次可以满足需求，为何还要花费开销去多进行一次握手呢 四次挥手 Client Server +-------------+ +-------------+ | ESTABLISHED | | ESTABLISHED | +-------------+ FIN M +-------------+ | | ------------------> | | | FIN_WAIT1 | | | | | | CLOSE_WAIT | +-------------+ ACK M+1 | | | | | | +-------------+ | | | | | CLOSE | | CLOSEE | | | +-------------+ +-------------+ 为什么建立连接是三次握手，而关闭连接却是四次挥手呢 在建立连接过程中，服务端发送SYN时一并把ACK也给发送到了客户端。而关闭时，当收到FIN时，仅仅表示对方不再发送数据了，但自己可能还有未发完的数据，对方还可以接收数据，所以此时不能把FIN和ACK一同发送给对方 第一次挥手，客户端发送一个FIN，并进入FIN_WAIT1状态 服务端收到客户端发送到FIN，并进入CLOSE_WAIT状态 第二次挥手，服务端回复ACK，客户端收到ACK 客户端进入FIN_WAIT2状态，并等待服务端发送FIN请求 第三次挥手，服务端发送FIN 客户端收到服务端发送到FIN，并进入TIME_WAIT状态 第四次挥手，客户端回复ACK 服务端收到ACK，连接关闭 参考 tcp为什么是三次握手，而不是两次或四次 三次握手，四次挥手“你真的懂吗?” Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/protocol/sctp.html":{"url":"docs/protocol/sctp.html","title":"为什么sctp不太为人所知道","keywords":"","body":"sctp原因使用场景参考sctp 为什么SCTP协议不太为人所知 原因 出生的晚 未广泛集成到TCP/IP协议栈中(在macos和windows中，到后来才被集成进去) 在易于使用的语言中很少有高级绑定 不能很好的穿越NAT 没有普通的公共应用程序使用它 SCTP堆栈的实现很复杂 有了MTCP 没有多少工具链可以玩SCTP，学习曲线陡增 其实就是TCP/UDP出来的早，先入为主，已经有了很完善的生态，而SCTP虽然有TCP/UDP两者的优点，但TCP/UDP的各种缺点并不是很迫切且大多能够通过技术或技巧解决掉。所以大家都不太愿意使用SCTP。 使用场景 SCTP在某些场景还是很适合的，比如私有网络中可以使用，在这方面它要比TCP协议的各方面做的更好(可靠性、安全性等) 电信领域使用的较多 参考 为什么SCTP没有被大量使用 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/protocol/mtu_find.html":{"url":"docs/protocol/mtu_find.html","title":"什么是路径MTU发现","keywords":"","body":"什么是MTU发现什么是MTU发现 MTU(maximum transmission unit)最大传输单元 因为网络层没有重传机制，如果一个分片丢失，整个ip数据包都会作废。 分片会加重路由器的负担，因此不希望路由器对ip数据包进行分片处理。 解决分片问题的技术是“路径MTU发现”。主机会首先获取路径中所有数据链路中的最小MTU，并按照整个大小将数据分片。因此传输过程中的任何一个路由器都不用进行分片工作。 为了找到路径MTU，主机首先发送整个数据包，并将ip首部的禁止分片标志设置为1，这样路由器在遇到需要分片才能处理的包时不会分片，而是直接丢弃并通过ICMP协议将整个不可达的消息发送给主机。 主机将ICMP通知中的MTU设置为当前的MTU，根据整个MTU对数据进行分片处理。如此反复，直到不再收到ICMP通知，此时的MTU就是路径MTU。 MTU MTU MTU 主机 ----> r1 ----> r2 ---> r3 ... ... Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/other/copy_on_write.html":{"url":"docs/other/copy_on_write.html","title":"什么是写时复制","keywords":"","body":"写时复制应用场景写时复制 如果有多个调用者同时请求相同资源（如内存或磁盘上的数据存储），他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本（private copy）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。 这个过程对其他的调用者是透明的（transparently）。此作法的主要优点是如果调用者没有修改该资源，就不会有副本（private copy）被建立，因此多个调用者只是读取操作是可以共享同一份资源。 应用场景 多读少写的场景, 能够提升读的效率 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/other/false_wakeup.html":{"url":"docs/other/false_wakeup.html","title":"什么是虚假唤醒","keywords":"","body":"虚假唤醒虚假唤醒 有对应的唤醒，但条件不成立。这是因为可能由于线程调度的原因，被条件变量唤醒的线程在本线程内真正执行「加锁并返回」前，另一个线程插了进来，完整地进行了一套「拿锁、改条件、还锁」的操作。 这就导致被唤醒的线程去执行时发现条件已经不对了, 它就属于是被虚假唤醒. 简单来说: 一个线程唤醒了之后，另一个线程抢在前面把条件改到不满足了 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/other/cloud.html":{"url":"docs/other/cloud.html","title":"什么是云计算","keywords":"","body":"云计算雾计算云计算 什么是云计算? 比如你要算1+1，自己算或者自己拿计算器算，这叫本地计算，当你给远在杭州的我打电话让我帮你算，算完之后我再把结果给你，这就是云计算。 为什么叫云计算呢？ 你知道我在杭州，但却够不着摸不到，就像蓝天下的白云一样，你知道TA在那里，但却够不着摸不到。我和云，离你都有不短的距离。 雾计算 除了云计算，还有一个叫雾计算。 什么是雾计算？ 还以1+1的例子来说，但这次不是打电话来和我沟通，而是以书信的方式，你把你想要计算的1+1写到书信里面邮寄给我，等我计算好之后，再把结果邮寄给你，路途遥远，耗时很长，可能你已经在家里等结果等的一直在跺脚了。这时，我想到一个方法，我抽出我的大半元神，化为亿万道分身，遍布全球各地，其中正有数道分身在你家附近，虽然分身不及我真身才能万分之一，但对于计算你附近这片区域的计算量已绰绰有余，这时你不必再把书信千里迢迢的邮寄到杭州这里了，只需要交给你附近我的分身即可，让他计算完后把结果给你，这大大减少了你等待的时间，这就是雾计算。 为什么叫雾计算呢？ 雾和云是相对的，云在遥不可及的天边，雾在更贴近你的身旁，TA们的成分有诸多相似之处，所以，用这个名字在合适不过了。 其实还有边缘计算、海计算、霾计算等，TA们的概念大同小异，但目的多为一致的。 最后，这些只是对不接触此领域的人易于理解，想要深入理解，更需要专业的知识去深入研究，仅靠这些肤浅的描述，反而容易把理解带偏。 计算机领域的很多名字都是来源于其它领域的。毕竟计算机的历史不长，与其创造新的名词，不如源于生活拿来既用，不但易于理解，更是生动形象。 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/other/a_b.html":{"url":"docs/other/a_b.html","title":"什么是灰度发布","keywords":"","body":"什么是蓝绿部署什么是灰度发布什么是蓝绿部署 在不停止旧版本的情况下在某些机器上部署新版本，把一部分流量切换到新版本上，当新版本没有什么问题时，就把旧版本给全部升级到新版本。 什么是灰度发布 百度百科灰度发布(又名金丝雀发布)是指在黑与白之间，能够平滑过渡的一种发布方式。一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。 先让部署一小部分新版本，这一小部分没有发现什么问题，就逐步增大部署规模，直到全部部署上新版本；主要控制新版本出现问题时影响范围。 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/other/btree.html":{"url":"docs/other/btree.html","title":"为什么B树系这么多分类","keywords":"","body":"B树系列B树B+树B*树应用场景B树系列 \"阶\"表示一个节点最多有多少个子节点 B树 B树又被称为B-树或B_树 一棵m阶B树是一棵平衡的m路搜索树。它或者是空树，或者满足以下性质: 根节点至少有两个子女 每个非根节点所包含的关键字个数j满足: m/2 - 1 任一节点(不包括叶子节点)的子节点个数正好是该节点关键字总和数加1，所以内部子树个数k满足: m/2 所有叶子节点都在同一层 B+树 B+树是B树的一个升级版，相对于B树来说B+树更充分的利用了节点的空间，让查询速度更加稳定 有n个子节点的节点必有n个key 数据存储在叶子节点，非叶子节点仅存储索引信息, 因此每个节点可以存储更多的key 树的所有叶子节点构成一个有序链表，可以按照key排序的次序遍历所有记录，方便于区间查找和遍历 B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。 B*树 B*树是B+树的变种 B*树定义了非叶子结点关键字个数至少为(2/3)*M，即块的最低使用率为2/3（代替B+树的1/2） 在B+树的基础上，B*树中非根和非叶子节点再增加指向兄弟的指针 B*树的分裂：当一个节点满时，如果它的下一个兄弟节点未满，那么将一部分数据移到兄弟节点中，再在原结点插入关键字，最后修改父结点中兄弟节点的关键字（因为兄弟节点的关键字范围改变了）如果兄弟也满了，则在原节点与兄弟节点之间增加新节点，并各复制1/3的数据到新节点，最后在父节点增加新节点的指针。 应用场景 B树系列比较适用于对树的高度要求较低的场景(比如每增加一层就会增加一次I/O等耗时的操作) 当很少遍历全部元素且经常查询靠近根节点的数据时, 选择B树更合适 当经常遍历全部元素或需要高度更低的树时, 选择B+树 如数据库系统和文件系统用B+树较多 在叶子节点和根节点之外的节点间需要兄弟节点进行遍历时, 选择B*树, B*树比B+树要复杂 B树系列还有2-3树、2-3-4树、UB树等等。当现有的树不满足使用场景时，就会衍生出其他树来适应对应的场景。 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/other/raid.html":{"url":"docs/other/raid.html","title":"什么是RAID","keywords":"","body":"RAIDRAID是什么RAID有哪些RAID0RAID1RAID3RAID5RAID6RAID10RAID RAID是什么 RAID(Redundant Array of Independent Disks)既独立磁盘冗余阵列，用多个独立的磁盘组成在一起形成一个大的磁盘系统，从而实现比单块磁盘更好的存储性能和更高的可靠性。 RAID有哪些 RAID0 RAID0，它将多块磁盘组合在一起形成一个大容量的存储。在写数据的时候，会将数据分成n份，以独立的方式实现n块磁盘的读写，这n份数据可以并行的写到磁盘中，所以效率很高。 RAID0不能提供数据校或冗余备份，因此某块磁盘损坏，数据就丢失无法恢复。适用于对可靠性要求不高但对读写性能要求高的场景。 RAID1 RAID1是磁盘阵列中单位成本很高的一种方式。它在往磁盘写数据的时候，将同一份数据无差别的写到两份到磁盘，分别写到工作磁盘和镜像磁盘，这将导致实际空间的使用率只有50%。 因为这种特性，RAID1给数据做了冗余备份，即使一块磁盘损坏，也可以再基于另一块磁盘去恢复数据，数据的可靠性很强，但是性能比较弱。 RAID3 RAID3是将数据按照RAID0的形式，分成多份同时写入多块磁盘，但是还会再留出一块磁盘用于写[奇偶校验码]。 例如总共有n块磁盘，那么就让其中n－1块磁盘并发的写数据，第n块磁盘记录校验码数据。一旦某一块磁盘损坏，就可以利用其他的n－1块磁盘去恢复数据。 因为记录校验码磁盘在有任何数据的写入都会去更新这块磁盘，导致这块磁盘读写最频繁，更容易损坏。 RAID5 RAID5对RAID3进行了改进，不需要单独的磁盘写校验码，它把校验码信息分布到各个磁盘上。 例如总共有n块磁盘，那么将要写入到数据分成n份并行的写入到n块磁盘，同时还将数据的校验码信息也写入到这n块磁盘中，一旦某一块磁盘损坏，可以用剩下的数据和对应的奇偶校验码信息去恢复损坏的数据。 RAID5最少需要三块磁盘来组建磁盘阵列，允许最多同时损坏一块磁盘。 RAID6 RAID6在RAID5的基础上进行了改进，引入了双重校验码的概念。 除了每块磁盘上都有同级数据xor校验区以外，还有针对每个数据块的xor校验区，相当于每个数据块都有两个校验保护措施。 虽然这样的数据冗余性好、读取效率也高，但是有较高的复杂度，并且写数据的性能较差。 RAID10 RAID10(RAID0+1)是RAID1和RAID0的一个合体。 首先基于RAID1将磁盘分成了两份，当要写入数据时，将所有数据在两份磁盘同时写入，相当于写了双份数据，起到了数据安全保障作用。并且每一份磁盘上又会基于RAID0将数据分为n份并行读写，这样保障了效率。 这样也有一半的空间用于冗余数据，成本较高。 Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "},"docs/style.html":{"url":"docs/style.html","title":"我的代码风格","keywords":"","body":"命令规则命令规则 说明 名词 示例 小驼峰 testHelloWorld 大坨峰 TestHellWorld 下划线 test_hello_world 大写下划线 TEST_HELLO_WORLD 规范 命名类型 命名 普通变量 小驼峰 类名 大坨峰 类成员函数 小驼峰 私有成员变量 _ + 小驼峰 函数 小驼峰 宏定义 大写下划线 全局变量 g_ + 小驼峰 结构体名 大坨峰 + _T 结构体成员 小驼峰 枚举名 大坨峰 + _E 枚举成员 大写下划线 头文件重复引用 __ + 大写下划线 + __ 命名空间 小写 普通指针 p开头(pTest, g_pTest) 智能指针 Ptr结尾(myPtr,myPtr_) 替代宏的常量 大坨峰 一般源文件命名 小驼峰 特殊源文件命名 前缀_ + 小驼峰 或 前缀小驼峰 觉得还是下划线比驼峰好看一点... Copyright © 2020-2021 ChangDingFang all right reserved，powered by Gitbook最近一次修订时间: 2021-08-25 18:31:45 "}}